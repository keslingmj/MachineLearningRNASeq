---
title: "Toil_Selection"
author: "Michael Kesling"
date: "9/27/2019"
output: rmarkdown::github_document 
---
This particular document takes the Toil-normalized TCGA and GTEx breast cancer samples and runs machine learning algorithms on them.  Importantly, the only sample-to-sample normalization performed in quantile-quantile normalization relative to a single reference sample.  No batch normalization is performed at this point,  as it's the simplest scenario for test samples processed in the clinic.

The data were downloaded from the UCSC server at:
https://xenabrowser.net/datapages/?cohort=TCGA%20TARGET%20GTEx&removeHub=https%3A%2F%2Fxena.treehouse.gi.ucsc.edu%3A443
There are 2 relevant *gene expression RNAseq* datasets there.  *RSEM expected_count (n=19,109)* which is used in this document, and *RSEM expected_count (DESeq2 standardized) (n=19,039)* which was used in the *Toil_Norm.Rmd* file.


The *markdown* and *html* versions of this document have some of the code masked for better readability.  To view the full code, see the [.Rmd version].

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(matrixStats)

######## FUNCTIONS NOT TO BE PRINTED IN MARKDOWN DOC:
scaleData <- function(DM, MEAN=TRUE, ROW=FALSE){
   # this function takes a data matrix, DM, and scales the data by each row's
   # standard deviation (if ROW=TRUE).  If ROW=FALSE, then all scaling will be
   # performed by column.  It may also first subtract off the (row)'s mean if
   # MEAN=TRUE.  For (rows) whose SD=0, they are set aside and added back once
   # the normalization is finished
   # We assume that counts have already been normalized across samples!!
   rowcol <- ifelse(ROW==TRUE, 1, 2)          # normalization by row or column
   rowcolInv <- ifelse(rowcol==1, 2, 1)       # inverse val needed for norm
   SD <- apply(DM, rowcol, sd)                # calc std deviations
   #print(c("SD",SD))
   numSDzeros <- sum(SD==0)
   #print(c("numSDzeros",numSDzeros))
   # remove row / col if SD == 0
   if(!is.na(numSDzeros) &numSDzeros != 0){                        # rm row/col if SD == 0
      zeroSD <- which(SD == 0)                # id examples with zero SD
      DM <- ifelse(rowcol==2, list(DM[, -zeroSD]), list(DM[-zeroSD,]))[[1]]
      SD <- SD[-zeroSD]
   }

   means <- apply(DM, rowcol, mean)
   
   # apply normalization with or without mean subtraction:
   if(MEAN==FALSE){
      DM <- t(apply(DM, rowcolInv, function(x){x / SD}))
   }
   else{
      DM <- t(apply(DM, rowcolInv, function(x){(x - means) / SD}))
   }

   if(rowcol == 1){           # transpose matrix if normalization is across rows
      DM <- t(DM)
   }
   
   # add back all-zero row / column taken out earlier (if done at all)
   if(!is.na(numSDzeros) &numSDzeros != 0){
      if(rowcol ==1){
         zeros <- matrix(rep(0, length(zeroSD)*dim(DM)[2]), ncol=dim(DM)[2])
         rownames(zeros) <- names(zeroSD)
         DM <- rbind(DM, zeros)
      }
      else{
         zeros <- matrix(rep(0, length(zeroSD)*dim(DM)[1]), nrow=dim(DM)[1])
         colnames(zeros) <- names(zeroSD)
         DM <- cbind(DM, zeros)
      }
   }
   return(DM)
}
```
### Subsetting Toil Data

As I'm only looking at just under 400 Breast Cancer samples that were previously selected, I'll subset the very large Toil RSEM file (19k samples).

The samples I'm interested in are located in a file called wangBreastFPKM398_Attrib.txt, created earlier.  While this file contains FPKM counts, I'm only pulling out the sample names from it.

Additionally, I'm going to convert the Ensemble IDs to the more readable HUGO gene IDs.

I start by grabbing the Wang sample names, the Toil sample names, and finding the overlap between the two.

```{r, include=FALSE}
require(dplyr)
require(magrittr)
wangMatrix <- read.table("/Users/mjk/Desktop/Tresorit_iOS/projects/RNA-Seq/data/wangBreastFPKM398_Attrib.txt", header=TRUE) # rownames okay now
wangSelectedSamples <- colnames(wangMatrix)
wangTCGAsamples <- wangSelectedSamples[grep("^TCGA", wangSelectedSamples)] %>%
   {gsub("\\.", "-", .)} %>% 
   {gsub("([TCGA]-[^-]+[-][^-]+[-][^-]+)[-].*", "\\1", .)} %>% 
   {gsub("[AB]$", "", .)}

wangGTEXsamples <- wangSelectedSamples[grep("^GTEX", wangSelectedSamples)] %>%
   {gsub("\\.", "-", .)}

wangSamples <- c(wangGTEXsamples, wangTCGAsamples)


toilSampleNames <- read.table("/Users/mjk/RNA-Seq_2019/TOIL_Data/TcgaTargetGtex_gene_expected_count", sep="\t", nrows = 1, stringsAsFactors = FALSE)
#toilSampleNames <- toilSampleNames[1,2:length(toilSampleNames)]


multiGrep <- function(var1, var2){
   return(grep(var1, var2))
}

wangSampleMapping <- sapply(wangSamples, multiGrep, var2=toilSampleNames)

# missing samples in TOIL set:
missingSamples <- wangSampleMapping[grep("integer", wangSampleMapping)] #15 missing
wangSamplesPresent <- setdiff(wangSamples, names(missingSamples))
```
15 of the Wang samples are missing in the Toil dataset.  I'll therefore be working with 382 remaining samples.  


Next, I read in the toil dataset (8GB+) and subset it by the Wang sample labels (data seen in .Rmd file).
```{r, include=FALSE}
# code only run the first time:
while(FALSE){
   toilData <- read.table("/Users/mjk/RNA-Seq_2019/TOIL_Data/TcgaTargetGtex_gene_expected_count", header=TRUE, stringsAsFactors = FALSE)

   
   # QA:
   sum(gsub("-", "\\.", toilSampleNames) %in% colnames(toilData)) == length(toilSampleNames)
   
   
   relevantCols <- unique(sort(c(1,unlist(wangSampleMapping[grep("integer", wangSampleMapping, invert=TRUE)], use.names = FALSE)))) #includes capturing gene names
   
   write.table(paste(relevantCols, collapse=","), "wangSamplesRSEM.uniq", sep=",",
               row.names = FALSE, col.names = FALSE)
   
   
   toilSubset <- toilData[, relevantCols]              # subset data
   
   #check that all cols got selected:
   all(gsub("-", ".", wangSamplesPresent) %in% colnames(toilSubset))
   
   write.table(toilSubset, "toilSubsetRSEM382.txt", sep="\t", row.names=FALSE)
   rm(toilData)
}
```

```{r}
# just read already-subsetted dataframe
toilSubset <- read.table("toilSubsetRSEM382.txt", sep="\t", header=TRUE)
rownames(toilSubset) <- toilSubset$sample
```
Next, I add gene names to the dataframe based on the Ensembl ID:
```{r}
require(dplyr)
toilGeneAnnot <- read.table("~/RNA-Seq_2019/TOIL_Data/gencode.v23.annotation.gene.probemap",
                            header=TRUE)
id2gene <- setNames(as.list(as.character(toilGeneAnnot$gene)),
                    toilGeneAnnot$id)
toilSubset <- toilSubset %>% tibble::rownames_to_column()
toilSubset <- toilSubset %>% mutate(gene=id2gene[toilSubset$rowname])
```
Next, I reorder the toilSubset data frame to group "like" samples and make the gene name the row name.
```{r}
colReOrder <- grep("^GTEX", colnames(toilSubset))
colReOrder <- c(colReOrder, grep("11$", colnames(toilSubset)))
colReOrder <- c(colReOrder, grep("01$", colnames(toilSubset)))
tmp <- toilSubset[,colReOrder]
rownames(tmp) <- paste0(toilSubset$gene, "-", toilSubset$rowname)
toilSubset <- tmp
rm(tmp)
```

### Create Test and Training Sets
At this point, all we've done is grabbed the Toil RSEM output data and subsetted
it with the Wang sample lists.  It's still in log2-format.

Next:
1. break into Test and Train  
2. perform edgeR normalization with a reference sample to control for depth-of-sequencing effects.  Use same reference for training and (future) test set  
3.filter out genes (independent if possible)
4. look at overall structure using t-SNE and PCA
5. Perform ML

```{r}
toilSubsetWide <- t(toilSubset)

require(caTools)
set.seed(233992812)
outcome <- c(rep(0, 185), rep(1, 197))  # 0 = healthy, 1 = tumor

# bind outcome variable on data frame for even, random partitioning
toilSubsetWide <- data.frame(cbind(toilSubsetWide, outcome))
idxTrain <- sample.split(toilSubsetWide$outcome, SplitRatio = 0.75)
# QA
sum(idxTrain)/length(idxTrain)  # 75% observations in training set OK

# create training and test predictor sets and outcome vectors:
toilTrain <- subset(toilSubsetWide, idxTrain==TRUE)
outcomeTrain <- subset(toilSubsetWide$outcome, idxTrain==TRUE)
toilTest <- subset(toilSubsetWide, idxTrain==FALSE)
outcomeTest <- subset(toilSubsetWide$outcome, idxTrain==FALSE)

# remove outcome variable from predictor matrices:
toilTrain <- toilTrain %>% select(-outcome)
toilTest <- toilTest %>% select(-outcome)
# convert back to matrices:
toilTrain <- as.matrix(toilTrain)
toilTest <- as.matrix(toilTest)
```
### edgeR Sample-to-Sample Normalization
Next, we select a reference sample within the training set and relative to that reference, we perform edgeR sample-to-sample normalization, one sample at a time.  The methodology can be found in Robinson MD and Oshlack A, "A scaling normalization method for differential expression analysis of RNA-seq data", Genome Biology, 11: R26 (2010).  

#### 1. Removing genes whose expression is very close to zero.  
We know that there are about 9103 genes that are never expressed (data not shown), but there are over 25000 genes whose 75th quantile-level expression is under 2^(0.2) - 1 = 0.14 counts. We really don't want to deal with those genes in selecting a reference sample, etc.
```{r}
hist(apply(toilTrain, 2, function(x) quantile(x)[4]), breaks=100, main="Histogram of gene's 75th quantile of expression.", xlab="log2(Est Counts)")
```
We are going to filter out genes whose 75th quantile across 287 samples is less than 0.14 counts (log2(counts) < 0.2).
```{r}
# Convert from log to natural scale:
toilTrainNat <- (2^toilTrain)-1
# Filter all 3rd quartile < 0.14 counts--filter criterion in log-scale:
ZEROEXPGENES <- which(apply(toilTrain, 2, function(x) quantile(x)[4]) < 0.2)
TOILTRAINFILTER <- toilTrainNat[,-ZEROEXPGENES]
quart3 <- apply(TOILTRAINFILTER, 1, function(x) quantile(x)[4])
hist(log2(quart3 + 1), main="75th Quantile Expression Per Sample")
```
We see that due to variation in depth-of-sequencing, some sample's 75th quantil can be a bit higher than others.  Note that the histogram is on the log2-scale.  


Having filtered out ~28k genes whose expression is nil or very, very close to that.  The range stays the same, which is 2.5 on the log scale.  Only subtraction, and not division, is relevant on this scale.  This matrix, called "TOILTRAINFILTER" is on the natural scale, has only the 287 training samples, and 32177 genes.  We will stick to these same genes when filtering test data before sample-to-reference normalization.  

#### 2. Selecting a Reference Sample for Sample-to-Sample Normalization
```{r}
# we remove matrices and lists we no longer need:
rm(toilGeneAnnot)
# rm(toilSampleNames) --used below for cancer stage determination
rm(quart3)

### Define Functions
pickRefSample <- function(X, logged=FALSE){  # X is matrix with samples as rows
                   # representative reference sample selected via edgeR specs
                   # this script assumes data are on natural scale.
   Xnat <- if(logged==TRUE) ((2^X)-1) else X  # put in natural scale
   N <- apply(Xnat, 1, sum)
   scaledX <- apply(Xnat, 2, function(x) x / N)
   thirdQuartiles <- apply(scaledX, 1, function(x) quantile(x)[4])
   med <- median(thirdQuartiles)
   refSampleName <- names(sort(abs(thirdQuartiles - med))[1])
   return(list(refSampleName, scaledX))
}
### 2. select a reference sample against which other samples will be scaled
lst <- pickRefSample(TOILTRAINFILTER, logged=FALSE) 
REFNAME <- lst[[1]]                                                         #### USED LATER
TOILTRAINSCALED <- lst[[2]]
REFSAMPLE <- TOILTRAINSCALED[which(rownames(TOILTRAINSCALED) == REFNAME),]  #### USED LATER
REFSAMPLEUNSCALED <- TOILTRAINFILTER[REFNAME,]                              #### USED LATER
print(paste0("The sample chosen to the the Reference Sample for the purposes of Sample-to-Sample Normalization is ",
        REFNAME, "."))
```
### 3. Scaling Training Samples Relative to the Chosen Reference Sample (Sample-to-Sample Normalization)
```{r}
weightedTrimmedMean <- function(refSample, testSample, refName, testName, testSmpUnscaled, refSmpUnscaled){
   # refSample and testSample are both numeric vectors, and we assume data are on natural
   # scale.  The values are represented as fraction of total counts.  So
   # df should be 'TOILTRAINFILTER' which are not as fracction of total counts, as
   # this is needed in computing the weights and TMM in the final step.
   # BTW, "testSample" does not infer that the sample is from the test set, but only
   # that it's a sample being scaled relative to the refSample.
   # refSmpUnscaled could be derived from df, but only with training sets and not 
   # with test sets.  So it is supplied separately.
   
   
   # first filter off any genes that are zero in refSample or testSample
   # # but for Yg• ≠ 0.

   refZeros <- which(refSample==0)
   smpZeros <- which(testSample==0)
   unionZeros <- sort(unique(append(refZeros, smpZeros)))
   refSampleFilt <- refSample[-unionZeros]
   testSampleFilt <- testSample[-unionZeros]
   
   # calculate M and A only for filtered genes   
   refLog <- log2(refSampleFilt)
   smpLog <- log2(testSampleFilt)

   M <- refLog - smpLog           # ref sample in numerator
   A <- 0.5 * (refLog + smpLog)   
   
   # grab middle 40% of M and middle 90% of A
   M_limits <- quantile(M, probs = seq(0,1,0.05))[c(7,15)]  # diagnostic
   A_limits <- quantile(A, probs = seq(0,1,0.05))[c(2,20)]  # diagnostic
   
   A_middle90 <- names(A[(A >= A_limits[1] & A <= A_limits[2]) == TRUE])
   M_middle40 <- names(M[(M >= M_limits[1] & M <= M_limits[2]) == TRUE])
   
   
   # grab genes names in intersection of A_middle90 and M_middle40
   genes4norm <- dplyr::intersect(A_middle90, M_middle40)

   #########
   # Nk and Nr must be relative to the genes that remain.
   # further, Ygk and Ygr need to be recalculated relative to that value
   #########
   # grab 2 samples on Norm Genes on Natural Scale that aren't a fraction of
   # the total sample counts.  refSmpUnscaled is separately supplied so that
   # this function will work with scaling test sets.
   refSelectNat <- refSmpUnscaled[genes4norm]
   testSelectNat <- testSmpUnscaled[genes4norm]
   
   # subset M for normalization genes
   M_norm <- M[genes4norm]
   
   # calculate Nk and Nr
   Nr <- sum(refSelectNat)
   Nk <- sum(testSelectNat)

   # calculate weights
   RefDiff <- Nr - refSelectNat
   TestDiff <- Nk - testSelectNat
   RefProd <- Nr * refSelectNat
   TestProd <- Nk * testSelectNat
   weights <- (RefDiff/RefProd) + (TestDiff/TestProd)

   # calculate Trimmed Mean scaling factor
   TMM_log2 <- sum(M_norm * weights)/sum(weights)   # some NaN here
   TMM <- 2^TMM_log2
   return(TMM)
}
```
#### 3. go through each sample in training set and get scaling factor
```{r}
ScalFact <- list()
samples <- rownames(TOILTRAINFILTER)
i <- 1
for(trainSampleName in samples){
   trainSample <- TOILTRAINSCALED[i,]
   trainUnscaled <- TOILTRAINFILTER[i,]
   scalingFactor <- weightedTrimmedMean(REFSAMPLE, trainSample, REFNAME, trainSampleName, trainUnscaled,
                                        REFSAMPLEUNSCALED)
   ScalFact <- c(ScalFact, scalingFactor)
   i = i+1
}
ScalFact <- unlist(ScalFact)

### 4. Scale toilTrainFilter matrix using scaling factors
#dim(toilTrainFilter)
toilTrainFiltScaled <- apply(TOILTRAINFILTER, 2, function(x) x/ScalFact)

```
we now have a scaled training matrix
```{r, include=FALSE}
### Distribution of 75th Quantiles of Scaled Training Samples
require(ggplot2)
# Let's start with distribution of median counts for each gene.
# quant75LevelsGenes <- apply(log2(toilTrainFiltScaled + 1), 1, quantile)[4,]
# hist(quant75LevelsGenes, breaks=100, main="75th quantile log2(normalized counts)")
# Remember that these values are on the log2 scale!  Therefore, genes under log2(exp) = 5 are likely very noisy.  For now, I'm only going to filter out the lowest genes:
```
### t-SNE to view Cancer/Healthy Diagnosis Partitioning among training samples
t-SNE is a way of speading out the data, which are in many dimensions, such that they can be approximately viewed in 2 dimensions.  It gives us a rough idea as to how different samples are spread across the predictor space.  
```{r}
require(Rtsne);
require(ggplot2);
set.seed(31234)
tSNEout_toilSN <- Rtsne(toilTrainFiltScaled, dims=2)
prognosis <- c(rep(1, 59), rep(2,80), rep(3, 148))       # 1/2 = healthy, 3 = cancer
tsne_plot_toil <- data.frame(x=tSNEout_toilSN$Y[,1], y = tSNEout_toilSN$Y[,2], col=prognosis)
colors3pal <- c("#FDAE6B", "#E6550D",  "#56B4E9")
#tsne_plot_3class <- data.frame(x=tSNEout_full$Y[,1], y = tSNEout_full$Y[,2], col=prognosis)
ggplot(tsne_plot_toil) + 
   geom_point(aes(x=x, y=y, color=as.factor(col))) + 
   ggtitle("t-SNE Plot of Training Data Using All Filtered Predictors of Toil Training Data") +
   scale_color_manual(name="Category",
                      breaks = c("1", "2", "3"),
                      values = c(colors3pal[1], colors3pal[2], colors3pal[3]),
                      labels = c("Healthy-GTEX", "Healthy-TCGA", "Cancer-TCGA"))
```
  
We can see that although these samples were not subject to batch normalization (such as ComBat, SVA), there is good segregation of healthy samples and tumors even though the healthy samples come from 2 different projects: TCGA and GTEx.  On the other hand, we see that there is segregation between those groups, but it still allows a separation of healthy / tumor.


### PCA Analysis
I'd like to compare the t-SNE plot to one using the 1st and 2nd principal components, as PC's are to scale and t-SNEs are not.  
I'll quickly scale the data first, as PCA requires that.  
```{r}
trainScaled <- scaleData(toilTrainFiltScaled, TRUE, FALSE)
PCs <- prcomp(trainScaled)
nComp <- 2
dfComponents <- predict(PCs, newdata=trainScaled)[,1:nComp]
PC_plot <- data.frame(x=dfComponents[,1], y = dfComponents[,2], col=prognosis)
colors3pal <- c("#FDAE6B", "#E6550D",  "#56B4E9")
#tsne_plot_3class <- data.frame(x=tSNEout_full$Y[,1], y = tSNEout_full$Y[,2], col=prognosis)
ggplot(PC_plot) + 
   geom_point(aes(x=x, y=y, color=as.factor(col))) + 
   ggtitle("PCA Plot of Training Data Using All Filtered Predictors of Toil Training Data") +
   scale_color_manual(name="Category",
                      breaks = c("1", "2", "3"),
                      values = c(colors3pal[1], colors3pal[2], colors3pal[3]),
                      labels = c("Healthy-GTEX", "Healthy-TCGA", "Cancer-TCGA"))
```
  
Again, the healthy samples partition well from the tumors.  And again, GTEX-healthy and TCGA-healthy are in distict clusters, showing that a batch effect still persists.  However, not addressing the batch effect allows us to either (a) keep the test set entirely separated from the training set through this entire procedure (one the data are split in step 1 above) or (b) process a single test sample without using other test samples for normalization.  

### Logistic Regression with Lasso Regularizer on Toil Data
I'd like to compare the performance on this breast cancer dataset in the absence of batch normalization (ComBat).
```{r, fig.height=8, fig.width=8}
###############
### Fitting Logistic Regression with Lasso Regularizer on toilSubNatural matrix
require(glmnet);
require(ggplot2);
# install_github("ririzarr/rafalib")
require(rafalib);

# scale each gene by its standard deviation and center it by its mean so that all coefficients
# are on equal footing
toilTrainFiltScaledSD <- scaleData(toilTrainFiltScaled, TRUE, FALSE)
set.seed(1011)
fitToil.lasso <- glmnet(toilTrainFiltScaledSD, outcomeTrain, family="binomial",
                           alpha = 1)
plot(fitToil.lasso, xvar="lambda", label=TRUE)

```
It's clear that scaling the predictors before Lasso enables many more to be used.  It would be interesting to see how many of these genes have a low level of expression (and therefore might be noisy data).

### Cross-Validating the Model to Pick the Smallest, Well-Performing Model
I'm going to look at cross-validating the model in order to pick the simplest one that performs well.
```{r, fig.height=8, fig.width=8}
set.seed(1011)
cv.Toil.lasso <- cv.glmnet(toilTrainFiltScaledSD, outcomeTrain, family="binomial", alpha=1) 
                      #type.measure = "deviance")
plot(cv.Toil.lasso)
```
We can see that 42 predictors gives us a model whose deviance is within 1-standard deviation from the minimum.  

### Select the Model by Capturing the Coefficients
```{r}
require(biomaRt)
coefsToil <- coef(fitToil.lasso, s=cv.Toil.lasso$lambda.1se)
allCoefsNames <- rownames(coefsToil)
idx <- which(coefsToil!= 0)
coefsFullNames <- allCoefsNames[idx]

coefsToilNonZero <- coefsToil[which(coefsToil!= 0)]
#class(coefsToilNonZero)                 #### get to sort numerically based on abs value, desc
coefsToilNZ_Abs <- abs(coefsToilNonZero)
coefsShortNames <- gsub("\\..*$", "", coefsFullNames)
# get Entrez ID ########################################## need for Panther

coefsDF <- data.frame(cbind(coefsToilNonZero, coefsToilNZ_Abs))
coefsDF <- cbind(coefsShortNames, coefsDF)
colnames(coefsDF) <- c("hgnc_symbol", "coefs", "coefs_abs")
genes42coef <- coefsDF %>% arrange(desc(coefs_abs))  #%>% dplyr::select(hgnc_symbol, coefs)              
```
### Retrieving Gene Information for the Model's Predictors
These are the 42 gene predictors in the model plus the Intercept, each with its coefficient after shrinkage.
```{r, include=FALSE}
# This section records various biomaRt fields that might be useful to query.
# While there was GO cellular location, I did not find GO MF or BP.
# biomaRt FILTERS:
# listFilters(ensembl)                     # for viewing all avail filters
# with_goslim_goa	With GOSlim GOA ID(s)		
# with_hgnc	With HGNC Symbol ID(s)
# with_ens_lrg_gene	With LRG display in Ensembl gene ID(s)		
# with_ens_lrg_transcript	With LRG display in Ensembl transcript ID(s)
# ensembl_gene_id	Gene stable ID(s) [e.g. ENSG00000000003]		
# ensembl_gene_id_version	Gene stable ID(s) with version [e.g. ENSG00000000003.15]
# go	GO ID(s) [e.g. GO:0000002]
# goslim_goa	GOSlim GOA ID(s) [e.g. GO:0000003]		
# hgnc_id	HGNC ID(s) [e.g. HGNC:100]		
# hgnc_symbol	HGNC symbol(s) [e.g. A1BG]
# go_parent_term	Parent term accession
# go_parent_name	Parent term name

# biomaRt attributes: 
# attributes = listAttributes(ensembl)  # for viewing avail attributes
# description	Gene description
# gene_biotype	Gene type
# name_1006	GO term name
# goslim_goa_accession	GOSlim GOA Accession(s)	feature_page		
# goslim_goa_description	GOSlim GOA Description
# hgnc_id	HGNC ID	feature_page		
# hgnc_symbol	HGNC symbol
# entrezgene_description	NCBI gene description	feature_page		
# entrezgene_accession	NCBI gene accession	feature_page		
# entrezgene_id	NCBI gene ID
# family_description	Ensembl Family Description
```

```{r}
# we'll grab biomaRt data for these genes
listMarts()
ensembl=useMart("ensembl")
ensembl = useDataset("hsapiens_gene_ensembl",mart=ensembl)

geneNames = c("MIR497HG","BGN","SRP9","ARHGAP20","PAFAH1B3","FXYD1","NDRG2","KLHL29","SRPX","TBL2","RILP","LMOD1","KCNJ2","AC093609","RP5","TRBV11","MAZ","CNTNAP3P2","TINAGL1","CHPF2","NKAPL","LIMK1","SLC17A7","FNDC1","CDK5","ZNF668","EDNRB","SDPR","USP44","CLDN8","TTYH3","H3F3A","GABARAPL1","ABCA5","ABCG1","PDK4","KLF15","NTNG2","ATP6V0B","CTD","ADAMTS5","FAM89B")

# This code is only performed the first time:
if(FALSE){
   geneID_Name_Description <- getBM(attributes=c("hgnc_id", "hgnc_symbol", "description"),
      values=geneNames,
      mart=ensembl)
write.csv(geneID_Name_Description, file="geneAttr.csv")
}

# in subsequent runs, the attributes can be read from the file:
geneID_Name_Description <- read.csv("geneAttr.csv", header=TRUE)

# sum(geneID_Name_Description$hgnc_symbol %in% geneNames)
# geneAnnot37 <- geneID_Name_Description %>% filter(hgnc_symbol %in% geneNames)
#geneAnnot37 <- geneID_Name_Description %>% filter(hgnc_symbol %in% genes42coef$geneName)
#geneAnnot37$hgnc_id <- gsub("^HGNC:","", geneAnnot37$hgnc_id)
#missing <- setdiff(geneNames, geneAnnot37$hgnc_symbol)   # 5 genes missing from biomaRt

# grab the gene symbol and description, add coefs, clean description, and print
#geneDescrip <- geneAnnot37 %>% dplyr::select(hgnc_symbol, description)

# test
coefGeneDescrip <- inner_join(geneID_Name_Description, genes42coef, by=c("hgnc_symbol", "hgnc_symbol")) %>%
   arrange(desc(coefs_abs)) %>%
   dplyr::select(coefs, hgnc_symbol, description)
coefGeneDescrip$description <- gsub(" \\[Source.*$","", coefGeneDescrip$description)
coefGeneDescrip
```
```{r, include=FALSE}
# the following code is to bring in GO functions, but I'm not going to incorporate
# that for the moment.
if(FALSE){
   # read in GO file for functions
   # these data were obtained from ftp://ftp.pantherdb.org/sequence_classifications/current_release/PANTHER_Sequence_Classification_files/ and from there, I selected the human file.
   GO_df <- read.csv("PTHR14.1_human_", sep="\t")
   # colnames(GO_df)  # need col #1, #5, #7 
   # reduce size of GO_df
   GO_df <- GO_df[,c(1,5,7)]
   GO_df[,1] <- gsub("HUMAN\\|HGNC=", "", GO_df[,1]) %>% {gsub("\\|UniProt.*$", "", .)}
   colnames(GO_df) <- c("hgnc_id", "subfamily", "BP")
   # join the 2 df together
   geneAnnot37_Expand <- inner_join(geneAnnot37, GO_df, by=c("hgnc_id", "hgnc_id"))
   geneAnnot37_Expand$description <- gsub(" \\[Source.*$","",geneAnnot37_Expand$description)
   write.csv(geneAnnot37_Expand, "geneAttr_Expand.csv")  # pair down BP manually
   geneName_desc35 <- geneAnnot37_Expand %>% dplyr::select(hgnc_symbol, description)
}
### just need to order this info and keep the coefficient as well### 
```
when performing predictions, we'll need *coefsFullNames* and *coefsToilNonZero*.
Remember when looking at these Lasso-Regularized Coefficients that each predictor gene was offset by its mean and scaled by its standard deviation.  That way, lower and more highly transcribed genes are on equal footing to influence the model.

### Filter and Scale Test Data.  (A) Relying on Training Data for Zero-Filtering and Scaling of Test Data
```{r}
### 1. Filter out near-zero genes as defined with training data:

## zero Filtering Must be re-indexed for test set
toilToFilterPosn <- which(colnames(toilTest) %in% names(ZEROEXPGENES))
toilTestFilter <- toilTest[,-toilToFilterPosn] # using Same Gene List Filter (near-zero) established in Training Set
# now 95 x 32177 on log2(x+1) scale


### 2. Scale test data as fraction of all sample counts
## define scaling function (same logic as with training data)
toilTestFiltNat <- 2^(toilTestFilter) - 1

scaleTestSamples <- function(X, logged=FALSE){  # X is matrix with samples as rows
                   # representative reference sample selected via edgeR specs
                   # this script assumes data are on natural scale.
   Xnat <- if(logged==TRUE) ((2^X)-1) else X  # put in natural scale
   N <- apply(Xnat, 1, sum)
   scaledX <- apply(Xnat, 2, function(x) x / N)
   return(scaledX)
}
toilTestScaled <- scaleTestSamples(toilTestFiltNat, logged=FALSE)


### 3. Individually scale test samples relative to training reference sample.  
# Each scaling is independent of other scalings.
# There is a filtering step (subsetCommonPredictors) that is applied first, 
# as we're using some of the references from the training set for the test set.

# subsetCommonPredictors <- function(refSmp, tstSmp, coefsFullNames){
#    
#    # AT this point, I've moved the common genes upstream
#    # the only thing that's happening here is that the (Intercept) is being 
#    # removed from the RefSample.
#    
#    commonNames = intersect(names(refSmp), names(tstSmp))
#    # need to add back any missing predictors
#    commonNamesPlus <- sort(unique(append(commonNames, coefsFullNames)))
#    print(c("commonQA", length(commonNames), length(commonNamesPlus)))
#    refUniqNames <- setdiff(names(refSmp), commonNamesPlus)
#    refUniqPosn <- which(names(refSmp) %in% refUniqNames)
# 
#    tstUniqNames <- setdiff(names(tstSmp), commonNamesPlus)
#    tstUniqPosn <- which(names(tstSmp) %in% tstUniqNames)
#    print(c("Other", refUniqPosn,tstUniqPosn))
#    print(c("final Lengths", length(refSmp[-refUniqPosn]), length(tstSmp[-tstUniqPosn])))
#    return(list(refSmp[-refUniqPosn], tstSmp[-tstUniqPosn]))
# } # I am losing some critical predictors at this stage


ScalFact <- list()
samples <- rownames(toilTestFilter)

## Are the coefficients already missing here?  -- YES.
# toilTest has them all
# toilTestScaled and Filter missing many
#which(colnames(toilTestFilter) %in% coefsFullNames[2:length(coefsFullNames)])



i <- 1
for(testSampleName in samples){  # some of the passed variables were created in training set
   testSample <- toilTestScaled[i,]
   testUnscaled <- toilTestFiltNat[i,]
   
   # ensure that intersection of genes the same across 4 lists
   #v <- subsetCommonPredictors(refSample, testSample, coefsFullNames)
   #refSample2 <- v[[1]]
   #testSample2 <- v[[2]]
   refSample2 <- REFSAMPLE[2:length(REFSAMPLE)]
   testSample2 <- testSample[names(refSample2)]
   testUnscaled2 <- testUnscaled[names(refSample2)]
   refSampleUnscaled2 <- REFSAMPLEUNSCALED[names(refSample2)]
   #print(all(names(testUnscaled2)==names(testSample2)))
   #print(c(length(refSample2), length(testSample2), length(refSampleUnscaled2),
           #   length(testUnscaled2)))
   
   scalingFactor <- weightedTrimmedMean(refSample2, testSample2, REFNAME, testSampleName,
                                        testUnscaled2, refSampleUnscaled2)
   ScalFact <- c(ScalFact, scalingFactor)
   i = i+1
}
ScalFact <- unlist(ScalFact)

### 4. Scale toilTrainFilter matrix using scaling factors
# dim(toilTestFiltNat)
toilTestFiltScaled <- apply(toilTestFiltNat, 2, function(x) x/ScalFact)

### 5. scale each gene by its standard deviation and center it by its mean so that all coefficients
#      are on equal footing
#toilTestFiltScaledSD <- scaleData(toilTestFiltScaled, TRUE, FALSE)       # this would not be possible for individual samples!!!!!!
#toilTestFiltScaledSD <- cbind(rep(1,dim(toilTestFiltScaledSD)[1]), toilTestFiltScaledSD) #add intercept column
```
### 4. Remove Non-Predictor Genes from Filtered Test Data
We're just keeping the 42 predictors from toilTestFiltScaled
```{r}
colIDs <- which(colnames(toilTestFiltScaled) %in% coefsFullNames[2:length(coefsFullNames)])
toilTestFiltScal42 <- toilTestFiltScaled[,colIDs]
```
### 5. Each Relevant Predictor Gene offset by Its Mean and Scaled by Its Standard Deviation
```{r}
# colnames(toilTestFiltScal42)
toilTestFiltScaledSD <- scaleData(toilTestFiltScal42, TRUE, FALSE)       
# this would not be possible for individual samples!!!!!!
toilTestFiltScaledSD <- cbind(rep(1,dim(toilTestFiltScaledSD)[1]), toilTestFiltScaledSD)
```
### Create Confusion Matrix for Test Data

```{r}
testPredictions_toil <- ifelse(toilTestFiltScaledSD %*% coefsToilNonZero > 0, 1, 0)
table(outcomeTest, testPredictions_toil)
```
I am seeing 100% specificity and 100% specificity!

### Filter and Scale Test Data.  (B) Not Relying on Training Data for Zero-Filtering or Scaling of Test Data
In order to see if the test data predictions might be biased by filtering relative to a list of genes identified using only training data or by scaling relative to a training reference sample, I'll repeat the process here, but using only *test data*.  In order to achieve this, when the predictions are made, we must only use predictors with non-zero coefficients, or the linear algebra will fail.

### 1. Filter Out Genes Whose Expression is Near-Zero 
```{r}
# next, let's filter all 3rd quartile < 0.14 counts--filter criterion in log-scale:
toilTestNat <- (2^toilTest)-1    # natural scale
# next, let's filter all 3rd quartile < 0.14 counts--filter criterion in log-scale:
zeroExpGenes <- which(apply(toilTest, 2, function(x) quantile(x)[4]) < 0.2)    #USED LATER
toilTestFilter <- toilTestNat[,-zeroExpGenes]
#quart3 <- apply(toilTestFilter, 1, function(x) quantile(x)[4])
#sd(quart3)/mean(quart3)              # CV drops slightly to 0.336
#hist(log2(quart3 + 1))
```
### 2. Select a Reference Sample Amongst Test Samples for Scaling Data
```{r}
lst <- pickRefSample(toilTestFilter, logged=FALSE) 
testRefName <- lst[[1]]                                                        
toilTestScaled <- lst[[2]]
testRefSample <- toilTestScaled[which(rownames(toilTestScaled) == testRefName),]  
testRefSampleUnscaled <- toilTestFilter[testRefName,]                              
print(paste0("The sample chosen to the the Reference Sample for the purposes of Sample-to-Sample Normalization is ",
        testRefName, "."))
```
### 3. Scaling Test Samples Relative to the Chosen TEST Reference Sample (Sample-to-Sample Normalization)

```{r}
ScalFact <- list()
samples <- rownames(toilTestFilter)
i <- 1
for(testSampleName in samples){
   testSample <- toilTestScaled[i,]
   testUnscaled <- toilTestFilter[i,]
   scalingFactor <- weightedTrimmedMean(testRefSample, testSample, testRefName, testSampleName, testUnscaled,
                                        testRefSampleUnscaled)    
   ScalFact <- c(ScalFact, scalingFactor)
   i = i+1
}
ScalFact <- unlist(ScalFact)

### Scale toilTrainFilter matrix using scaling factors
# dim(toilTestFilter)
toilTestFiltScaled <- apply(toilTestFilter, 2, function(x) x/ScalFact)
### we now have a scaled test matrix
```
### 4. Remove Non-Predictor Genes from Filtered Test Data
We're just keeping the 42 predictors from toilTestFiltScaled
```{r}
toilTestFiltScal42 <- toilTestFiltScaled[,coefsFullNames[2:length(coefsFullNames)]]
```
### 5. Each Relevant Predictor Gene offset by Its Mean and Scaled by Its Standard Deviation
```{r}
toilTestFiltScaledSD <- scaleData(toilTestFiltScal42, TRUE, FALSE)       
# this would not be possible for individual samples!!!!!!
toilTestFiltScaledSD <- cbind(rep(1,dim(toilTestFiltScaledSD)[1]), toilTestFiltScaledSD)
```
### Create Confusion Matrix for Test Data

```{r}
testPredictions_toil <- ifelse(toilTestFiltScaledSD %*% coefsToilNonZero > 0, 1, 0)
table(outcomeTest, testPredictions_toil)
```
I am still at 100% sensitivity and 100% specificity!  I used no training data for filtering or scaling the test samples.  The test set was treated separately from the beginning.

### Test Model Accuracy on TCGA Data Not Yet Examined  
At this point, we've exhausted all the healthy breast samples either in the training set or the test set.  
However, I'd like to test this model across the remaining TCGA tumors, grouped by *tumor stage* to see how well the model performs on those samples.  

##### Collecting Unused TCGA Samples, Grouped by Tumor Stage
I'll grab all TCGA sample names, remove those that have already been used in this study,
either as training or test samples, and then group the data by tumor stage.
```{r}
# read in TCGA attribute file:
TCGA_Attr_Full <- read.csv("~/Desktop/Tresorit_iOS/projects/RNA-Seq/data/TCGA_Attributes_full.txt",
         header=TRUE, sep="\t", stringsAsFactors = FALSE)
TCGA_ID_Stage <- TCGA_Attr_Full %>% select(tcgaID, tumor_stage)
rm(TCGA_Attr_Full)

# grab all TCGA IDs already used--already created as wangTCGAsamples
# there's also a toilSampleNames object as well.  # NOTE THAT FINAL LETTER STRIPPED OFF

# initialize six tumor stage dataframes
stageOne <- data.frame(tcgaID=character(), stage=character(), novel=character)
stageTwo <- data.frame(tcgaID=character(), stage=character(), novel=character)
stageThree <- data.frame(tcgaID=character(), stage=character(), novel=character)
stageFour <- data.frame(tcgaID=character(), stage=character(), novel=character)
stageZero <- data.frame(tcgaID=character(), stage=character(), novel=character)
stageHealthy <- data.frame(tcgaID=character(), stage=character())
stageUnknown <- data.frame(tcgaID=character(), stage=character())

######################################
# function for appending to dataframes
appendDFtumor <- function(id, stage){  # appends non-healthy smpl/df
   if(any(grepl(gsub("[ABZ]$","",id), wangTCGAsamples))){
      vect <- cbind(id, stage, novel="already_used")}  # need to eval df
   else{
      vect <- cbind(id, stage, novel="unused")}
   return(vect)
}
#######################################
#######################################
# break apart tcgaIDs, and classify by type (converted to factor)
processTumorStage <- function(df){  #expects  1 row of 2 col df: 
                                    # tcga_ID and tumor_stage
   
   stage = unlist(df[2])
   for(id in unlist(strsplit(df[1], ";"))){
      if(grepl("01[ABZ]$", id)){                 # filter our healthy samples
         stageHealthy <<- rbind(stageHealthy, cbind(id, "healthy"))
      }
      else{    
         if(grepl("stage i[ab]", stage) | grepl("stage i$", stage)){
            stageOne <<- rbind(stageOne, appendDFtumor(id, stage))}
         else if(grepl("stage ii[ab]", stage) | grepl("stage ii$", stage)){
            stageTwo <<- rbind(stageTwo, appendDFtumor(id, stage))}
         else if(grepl("stage iii[abc]", stage) | grepl("stage iii$", stage)){
            stageThree <<- rbind(stageThree, appendDFtumor(id, stage))}
         else if(grepl("stage iv[ab]", stage) | grepl("stage iv$", stage)){
            stageFour <<- rbind(stageFour, appendDFtumor(id, stage))}
         else if(grepl("stage x", stage) | grepl("not reported", stage)){
            stageUnknown <<- rbind(stageUnknown, cbind(id, stage))}
         else{
            print(c(id, stage, "missing class"))
         }
      }
   }
}
########################################


apply(TCGA_ID_Stage, 1, processTumorStage)
# rownames very ugly and not helpful!
```






