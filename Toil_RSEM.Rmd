---
title: "Toil_Selection"
author: "Michael Kesling"
date: "9/27/2019"
output: rmarkdown::github_document 
---
This particular document takes the Toil-normalized TCGA and GTEx breast cancer samples and runs machine learning algorithms on them.  Importantly, the only sample-to-sample normalization performed in quantile-quantile normalization relative to a single reference sample.  No batch normalization is performed at this point,  as it's the simplest scenario for test samples processed in the clinic.

The data were downloaded from the UCSC server at:
https://xenabrowser.net/datapages/?cohort=TCGA%20TARGET%20GTEx&removeHub=https%3A%2F%2Fxena.treehouse.gi.ucsc.edu%3A443
There are 2 relevant *gene expression RNAseq* datasets there.  *RSEM expected_count (n=19,109)* which is used in this document, and *RSEM expected_count (DESeq2 standardized) (n=19,039)* which was used in the *Toil_Norm.Rmd* file.


The *markdown* and *html* versions of this document have some of the code masked for better readability.  To view the full code, see the [.Rmd version].

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(matrixStats)
require(magrittr)
require(gridExtra)

######## FUNCTIONS NOT TO BE PRINTED IN MARKDOWN DOC:
scaleData <- function(DM, MEAN=TRUE, ROW=FALSE){
   # this function takes a data matrix, DM, and scales the data by each row's
   # standard deviation (if ROW=TRUE).  If ROW=FALSE, then all scaling will be
   # performed by column.  It may also first subtract off the (row)'s mean if
   # MEAN=TRUE.  For (rows) whose SD=0, they are set aside and added back once
   # the normalization is finished
   # We assume that counts have already been normalized across samples!!
   rowcol <- ifelse(ROW==TRUE, 1, 2)          # normalization by row or column
   rowcolInv <- ifelse(rowcol==1, 2, 1)       # inverse val needed for norm
   SD <- apply(DM, rowcol, sd)                # calc std deviations
   #print(c("SD",SD))
   numSDzeros <- sum(SD==0)
   #print(c("numSDzeros",numSDzeros))
   # remove row / col if SD == 0
   if(!is.na(numSDzeros) &numSDzeros != 0){                        # rm row/col if SD == 0
      zeroSD <- which(SD == 0)                # id examples with zero SD
      DM <- ifelse(rowcol==2, list(DM[, -zeroSD]), list(DM[-zeroSD,]))[[1]]
      SD <- SD[-zeroSD]
   }

   means <- apply(DM, rowcol, mean)
   
   # apply normalization with or without mean subtraction:
   if(MEAN==FALSE){
      DM <- t(apply(DM, rowcolInv, function(x){x / SD}))
   }
   else{
      DM <- t(apply(DM, rowcolInv, function(x){(x - means) / SD}))
   }

   if(rowcol == 1){           # transpose matrix if normalization is across rows
      DM <- t(DM)
   }
   
   # add back all-zero row / column taken out earlier (if done at all)
   if(!is.na(numSDzeros) &numSDzeros != 0){
      if(rowcol ==1){
         zeros <- matrix(rep(0, length(zeroSD)*dim(DM)[2]), ncol=dim(DM)[2])
         rownames(zeros) <- names(zeroSD)
         DM <- rbind(DM, zeros)
      }
      else{
         zeros <- matrix(rep(0, length(zeroSD)*dim(DM)[1]), nrow=dim(DM)[1])
         colnames(zeros) <- names(zeroSD)
         DM <- cbind(DM, zeros)
      }
   }
   return(DM)
}
```
### Subsetting Toil Data

As I'm only looking at just under 400 Breast Cancer samples that were previously selected, I'll subset the very large Toil RSEM file (19k samples).

The samples I'm interested in are located in a file called wangBreastFPKM398_Attrib.txt, created earlier.  While this file contains FPKM counts, I'm only pulling out the sample names from it.

Additionally, I'm going to convert the Ensemble IDs to the more readable HUGO gene IDs.

I start by grabbing the Wang sample names, the Toil sample names, and finding the overlap between the two.

```{r, include=FALSE}
require(dplyr)
require(magrittr)
wangMatrix <- read.table("/Users/mjk/Desktop/Tresorit_iOS/projects/RNA-Seq/data/wangBreastFPKM398_Attrib.txt", header=TRUE) # rownames okay now
wangSelectedSamples <- colnames(wangMatrix)
wangTCGAsamples <- wangSelectedSamples[grep("^TCGA", wangSelectedSamples)] %>%
   {gsub("\\.", "-", .)} %>% 
   {gsub("([TCGA]-[^-]+[-][^-]+[-][^-]+)[-].*", "\\1", .)} %>% 
   {gsub("[ABCZ]$", "", .)}

wangGTEXsamples <- wangSelectedSamples[grep("^GTEX", wangSelectedSamples)] %>%
   {gsub("\\.", "-", .)}

wangSamples <- c(wangGTEXsamples, wangTCGAsamples)


toilSampleNames <- read.table("/Users/mjk/RNA-Seq_2019/TOIL_Data/TcgaTargetGtex_gene_expected_count", sep="\t", nrows = 1, stringsAsFactors = FALSE)
#toilSampleNames <- toilSampleNames[1,2:length(toilSampleNames)]


multiGrep <- function(var1, var2){
   return(grep(var1, var2))
}

wangSampleMapping <- sapply(wangSamples, multiGrep, var2=toilSampleNames)

# missing samples in TOIL set:
missingSamples <- wangSampleMapping[grep("integer", wangSampleMapping)] #15 missing
wangSamplesPresent <- setdiff(wangSamples, names(missingSamples))
```
15 of the Wang samples are missing in the Toil dataset.  I'll therefore be working with 382 remaining samples.  


Next, I read in the toil dataset (8GB+) and subset it by the Wang sample labels (data seen in .Rmd file).
```{r, include=FALSE}
# code only run the first time:
while(FALSE){
   toilData <- read.table("/Users/mjk/RNA-Seq_2019/TOIL_Data/TcgaTargetGtex_gene_expected_count", header=TRUE, stringsAsFactors = FALSE)

   
   # QA:
   sum(gsub("-", "\\.", toilSampleNames) %in% colnames(toilData)) == length(toilSampleNames)
   
   
   relevantCols <- unique(sort(c(1,unlist(wangSampleMapping[grep("integer", wangSampleMapping, invert=TRUE)], use.names = FALSE)))) #includes capturing gene names
   
   write.table(paste(relevantCols, collapse=","), "wangSamplesRSEM.uniq", sep=",",
               row.names = FALSE, col.names = FALSE)
   
   
   toilSubset <- toilData[, relevantCols]              # subset data
   
   #check that all cols got selected:
   all(gsub("-", ".", wangSamplesPresent) %in% colnames(toilSubset))
   
   write.table(toilSubset, "toilSubsetRSEM382.txt", sep="\t", row.names=FALSE)
   rm(toilData)
}
```

```{r}
# just read already-subsetted dataframe
toilSubset <- read.table("toilSubsetRSEM382.txt", sep="\t", header=TRUE)
rownames(toilSubset) <- toilSubset$sample
```
Next, I add gene names to the dataframe based on the Ensembl ID:
```{r}
require(dplyr)
toilGeneAnnot <- read.table("~/RNA-Seq_2019/TOIL_Data/gencode.v23.annotation.gene.probemap",
                            header=TRUE)
id2gene <- setNames(as.list(as.character(toilGeneAnnot$gene)),
                    toilGeneAnnot$id)
toilSubset <- toilSubset %>% tibble::rownames_to_column()
toilSubset <- toilSubset %>% mutate(gene=id2gene[toilSubset$rowname])
```
Next, I reorder the toilSubset data frame to group "like" samples and make the gene name the row name.
```{r}
colReOrder <- grep("^GTEX", colnames(toilSubset))
colReOrder <- c(colReOrder, grep("11$", colnames(toilSubset)))
colReOrder <- c(colReOrder, grep("01$", colnames(toilSubset)))
tmp <- toilSubset[,colReOrder]
rownames(tmp) <- paste0(toilSubset$gene, "-", toilSubset$rowname)
toilSubset <- tmp
rm(tmp)
```

### Create Test and Training Sets
At this point, all we've done is grabbed the Toil RSEM output data and subsetted
it with the Wang sample lists.  It's still in log2-format.

Next:
1. break into Test and Train  
2. perform edgeR normalization with a reference sample to control for depth-of-sequencing effects.  Use same reference for training and (future) test set  
3.filter out genes (independent if possible)
4. look at overall structure using t-SNE and PCA
5. Perform ML

```{r}
toilSubsetWide <- t(toilSubset)

require(caTools)
set.seed(233992812)
outcome <- c(rep(0, 185), rep(1, 197))  # 0 = healthy, 1 = tumor

# bind outcome variable on data frame for even, random partitioning
toilSubsetWide <- data.frame(cbind(toilSubsetWide, outcome))
idxTrain <- sample.split(toilSubsetWide$outcome, SplitRatio = 0.75)
# QA
sum(idxTrain)/length(idxTrain)  # 75% observations in training set OK

# create training and test predictor sets and outcome vectors:
toilTrain <- subset(toilSubsetWide, idxTrain==TRUE)
outcomeTrain <- subset(toilSubsetWide$outcome, idxTrain==TRUE)
toilTest <- subset(toilSubsetWide, idxTrain==FALSE)
outcomeTest <- subset(toilSubsetWide$outcome, idxTrain==FALSE)

# remove outcome variable from predictor matrices:
toilTrain <- toilTrain %>% select(-outcome)
toilTest <- toilTest %>% select(-outcome)
# convert back to matrices:
toilTrain <- as.matrix(toilTrain)
toilTest <- as.matrix(toilTest)
```
### edgeR Sample-to-Sample Normalization
Next, we select a reference sample within the training set and relative to that reference, we perform edgeR sample-to-sample normalization, one sample at a time.  The methodology can be found in Robinson MD and Oshlack A, "A scaling normalization method for differential expression analysis of RNA-seq data", Genome Biology, 11: R26 (2010).  

#### 1. Removing genes whose expression is very close to zero.  
We know that there are about 9103 genes that are never expressed (data not shown), but there are over 25000 genes whose 75th quantile-level expression is under 2^(0.2) - 1 = 0.14 counts. We really don't want to deal with those genes in selecting a reference sample, etc.
```{r, fig.height=5, fig.width=5, dpi=300}
hist(apply(toilTrain, 2, function(x) quantile(x)[4]), breaks=100, main="Histogram of gene's 75th quantile of expression.", xlab="log2(Est Counts)")
```
We are going to filter out genes whose 75th quantile across 287 samples is less than 0.14 counts (log2(counts) < 0.2).
```{r}
# Convert from log to natural scale:
toilTrainNat <- (2^toilTrain)-1
# Filter all 3rd quartile < 0.14 counts--filter criterion in log-scale:
ZEROEXPGENES <- which(apply(toilTrain, 2, function(x) quantile(x)[4]) < 0.2)
TOILTRAINFILTER <- toilTrainNat[,-ZEROEXPGENES]
quart3 <- apply(TOILTRAINFILTER, 1, function(x) quantile(x)[4])
hist(log2(quart3 + 1), main="75th Quantile Expression Per Sample")
```
We see that due to variation in depth-of-sequencing, some sample's 75th quantil can be a bit higher than others.  Note that the histogram is on the log2-scale.  


Having filtered out ~28k genes whose expression is nil or very, very close to that.  The range stays the same, which is 2.5 on the log scale.  Only subtraction, and not division, is relevant on this scale.  This matrix, called "TOILTRAINFILTER" is on the natural scale, has only the 287 training samples, and 32177 genes.  We will stick to these same genes when filtering test data before sample-to-reference normalization.  

#### 2. Selecting a Reference Sample for Sample-to-Sample Normalization
```{r}
# we remove matrices and lists we no longer need:
rm(toilGeneAnnot)
# rm(toilSampleNames) --used below for cancer stage determination
rm(quart3)

### Define Functions
pickRefSample <- function(X, logged=FALSE){  # X is matrix with samples as rows
                   # representative reference sample selected via edgeR specs
                   # this script assumes data are on natural scale.
   Xnat <- if(logged==TRUE) ((2^X)-1) else X  # put in natural scale
   N <- apply(Xnat, 1, sum)
   scaledX <- apply(Xnat, 2, function(x) x / N)
   thirdQuartiles <- apply(scaledX, 1, function(x) quantile(x)[4])
   med <- median(thirdQuartiles)
   refSampleName <- names(sort(abs(thirdQuartiles - med))[1])
   return(list(refSampleName, scaledX))
}
### 2. select a reference sample against which other samples will be scaled
lst <- pickRefSample(TOILTRAINFILTER, logged=FALSE) 
REFNAME <- lst[[1]]                                                         #### USED LATER
TOILTRAINSCALED <- lst[[2]]
REFSAMPLE <- TOILTRAINSCALED[which(rownames(TOILTRAINSCALED) == REFNAME),]  #### USED LATER
REFSAMPLEUNSCALED <- TOILTRAINFILTER[REFNAME,]                              #### USED LATER
print(paste0("The sample chosen to the the Reference Sample for the purposes of Sample-to-Sample Normalization is ",
        REFNAME, "."))
```
### 1- 2A. ALTERNATIVE: subset TOILTRAINSCALED to just include most variable genes
For this to work well, I'm going to set a more stringent filter on the zero-expressed genes
THE MORE STRINGENT ZERO-FILTER OF LOG2-EXP < 5 GAVE RISE TO VERY UNSTABLE SAMPLE-TO-SAMPLE SCALING FACTORS
```{r}
# toilTrainNat <- (2^toilTrain)-1
# # Filter all 3rd quartile < 5 log-counts--filter criterion in log-scale:
# ZEROEXPGENES <- which(apply(toilTrain, 2, function(x) quantile(x)[4]) < 5)  #rm 41718 genes
# TOILTRAINFILTER <- toilTrainNat[,-ZEROEXPGENES]
# #quart3 <- apply(TOILTRAINFILTER, 1, function(x) quantile(x)[4])
# #hist(log2(quart3 + 1), main="75th Quantile Expression Per Sample")
# 
# # find 1000 most-variable genes on relative scale
# means <- apply(TOILTRAINFILTER, 2, mean)
# sds <- apply(TOILTRAINFILTER, 2, sd)
# CVs <- sds/means
# top1000CVs <- sort(CVs, decreasing = TRUE)[1:1000]
# TOILTRAINFILTER1k <- TOILTRAINFILTER[,names(top1000CVs)]
```

# WARNING: going to substitute for main training matrix here for trying out ideas!
This failed and I'll delete it later
```{r}
# TOILTRAINFILTER <- TOILTRAINFILTER1k
# 
# ### 2. select a reference sample against which other samples will be scaled
# lst <- pickRefSample(TOILTRAINFILTER, logged=FALSE) 
# REFNAME <- lst[[1]]                                                         #### USED LATER
# TOILTRAINSCALED <- lst[[2]]
# REFSAMPLE <- TOILTRAINSCALED[which(rownames(TOILTRAINSCALED) == REFNAME),]  #### USED LATER
# REFSAMPLEUNSCALED <- TOILTRAINFILTER[REFNAME,]                              #### USED LATER
# print(paste0("The sample chosen to the the Reference Sample for the purposes of Sample-to-Sample Normalization is ",
#         REFNAME, "."))
```








### 3. Scaling Training Samples Relative to the Chosen Reference Sample (Sample-to-Sample Normalization)
```{r}
weightedTrimmedMean <- function(refSample, testSample, refName, testName, testSmpUnscaled, refSmpUnscaled){
   # refSample and testSample are both numeric vectors, and we assume data are on natural
   # scale.  The values are represented as fraction of total counts.  So
   # df should be 'TOILTRAINFILTER' which are not as fracction of total counts, as
   # this is needed in computing the weights and TMM in the final step.
   # BTW, "testSample" does not infer that the sample is from the test set, but only
   # that it's a sample being scaled relative to the refSample.
   # refSmpUnscaled could be derived from df, but only with training sets and not 
   # with test sets.  So it is supplied separately.
   
   
   # first filter off any genes that are zero in refSample or testSample
   # # but for Yg• ≠ 0.

   refZeros <- which(refSample==0)
   smpZeros <- which(testSample==0)
   unionZeros <- sort(unique(append(refZeros, smpZeros)))
   refSampleFilt <- refSample[-unionZeros]
   testSampleFilt <- testSample[-unionZeros]
   
   # calculate M and A only for filtered genes   
   refLog <- log2(refSampleFilt)
   smpLog <- log2(testSampleFilt)

   M <- refLog - smpLog           # ref sample in numerator
   A <- 0.5 * (refLog + smpLog) 
   
   # print for KeyNote figure:
   # require(ggplot2)
   # df00 <- data.frame(cbind(A, M))
   # print(ggplot(df00, aes(x=A, y=M)) +
   #    geom_point(colour="blue", size=0.5) +
   #    theme_bw() + ylim(-12,12))
   
   
   # grab middle 40% of M and middle 90% of A
   M_limits <- quantile(M, probs = seq(0,1,0.05))[c(7,15)]  # diagnostic
   A_limits <- quantile(A, probs = seq(0,1,0.05))[c(2,20)]  # diagnostic
   
   # show how many points are between each of these quantiles (plot doesn't give)
   #hist(A, breaks = A_limits)#, xlim=c(-5,5)) # NEED WHOLE RANGE OF M_limits, A_limits for this to work.
   
   # QA:
   # print(c(M_limits, A_limits))
   
   A_middle90 <- names(A[(A >= A_limits[1] & A <= A_limits[2]) == TRUE])
   M_middle40 <- names(M[(M >= M_limits[1] & M <= M_limits[2]) == TRUE])
   
   # grab genes names in intersection of A_middle90 and M_middle40
   genes4norm <- dplyr::intersect(A_middle90, M_middle40)

   #########
   # Nk and Nr must be relative to the genes that remain.
   # further, Ygk and Ygr need to be recalculated relative to that value
   #########
   # grab 2 samples on Norm Genes on Natural Scale that aren't a fraction of
   # the total sample counts.  refSmpUnscaled is separately supplied so that
   # this function will work with scaling test sets.
   refSelectNat <- refSmpUnscaled[genes4norm]
   testSelectNat <- testSmpUnscaled[genes4norm]
   
   # subset M for normalization genes
   M_norm <- M[genes4norm]
   
   # calculate Nk and Nr
   Nr <- sum(refSelectNat)
   Nk <- sum(testSelectNat)

   # calculate weights
   RefDiff <- Nr - refSelectNat
   TestDiff <- Nk - testSelectNat
   RefProd <- Nr * refSelectNat
   TestProd <- Nk * testSelectNat
   weights <- (RefDiff/RefProd) + (TestDiff/TestProd)
   
   # for keynote presentation:
   # df01 <- data.frame(cbind(x=log2(refSelectNat), weight=RefDiff/RefProd))
   # print(ggplot(df01, aes(x=x,y=weight)) +
   #    geom_point() + theme_bw())

   # calculate Trimmed Mean scaling factor
   TMM_log2 <- sum(M_norm * weights)/sum(weights)                # some NaN here
   TMM <- 2^TMM_log2
   return(TMM)                  # returns a single scaling factor for testSample
}
```
#### 3. go through each sample in training set and get scaling factor
```{r}
ScalFact <- list()
samples <- rownames(TOILTRAINFILTER)
i <- 1
for(trainSampleName in samples){
   trainSample <- TOILTRAINSCALED[i,]
   trainUnscaled <- TOILTRAINFILTER[i,]
   scalingFactor <- weightedTrimmedMean(REFSAMPLE, trainSample, REFNAME, trainSampleName, trainUnscaled,
                                        REFSAMPLEUNSCALED)
   ScalFact <- c(ScalFact, scalingFactor)
   i = i+1
}
ScalFact <- unlist(ScalFact)      # SOME SCALING FACTORS VERY LARGE (20) AFTER BIGGER ZERO FILTER

### 4. Scale toilTrainFilter matrix using scaling factors
#dim(toilTrainFilter)
toilTrainFiltScaled <- apply(TOILTRAINFILTER, 2, function(x) x/ScalFact)

```
we now have a scaled training matrix
```{r, include=FALSE}
### Distribution of 75th Quantiles of Scaled Training Samples
require(ggplot2)
# Let's start with distribution of median counts for each gene.
# quant75LevelsGenes <- apply(log2(toilTrainFiltScaled + 1), 1, quantile)[4,]
# hist(quant75LevelsGenes, breaks=100, main="75th quantile log2(normalized counts)")
# Remember that these values are on the log2 scale!  Therefore, genes under log2(exp) = 5 are likely very noisy.  For now, I'm only going to filter out the lowest genes:
```
### t-SNE to view Cancer/Healthy Diagnosis Partitioning among training samples
t-SNE is a way of speading out the data, which are in many dimensions, such that they can be approximately viewed in 2 dimensions.  It gives us a rough idea as to how different samples are spread across the predictor space.  
```{r}
require(Rtsne);
require(ggplot2);
set.seed(31234)
tSNEout_toilSN <- Rtsne(toilTrainFiltScaled, dims=2)
prognosis <- c(rep(1, 59), rep(2,80), rep(3, 148))       # 1/2 = healthy, 3 = cancer
tsne_plot_toil <- data.frame(x=tSNEout_toilSN$Y[,1], y = tSNEout_toilSN$Y[,2], col=prognosis)
colors3pal <- c("#FDAE6B", "#E6550D",  "#56B4E9")
#tsne_plot_3class <- data.frame(x=tSNEout_full$Y[,1], y = tSNEout_full$Y[,2], col=prognosis)
ggplot(tsne_plot_toil) + 
   geom_point(aes(x=x, y=y, color=as.factor(col))) + 
   ggtitle("t-SNE Plot of Training Data Using All Filtered Predictors of Toil Training Data") +
   scale_color_manual(name="Category",
                      breaks = c("1", "2", "3"),
                      values = c(colors3pal[1], colors3pal[2], colors3pal[3]),
                      labels = c("Healthy-GTEX", "Healthy-TCGA", "Cancer-TCGA"))
```
  
We can see that although these samples were not subject to batch normalization (such as ComBat, SVA), there is good segregation of healthy samples and tumors even though the healthy samples come from 2 different projects: TCGA and GTEx.  On the other hand, we see that there is segregation between those groups, but it still allows a separation of healthy / tumor.


### PCA Analysis
I'd like to compare the t-SNE plot to one using the 1st and 2nd principal components, as PC's are to scale and t-SNEs are not.  
I'll quickly scale the data first, as PCA requires that.  
```{r}
trainScaled <- scaleData(toilTrainFiltScaled, TRUE, FALSE)
PCs <- prcomp(trainScaled)                               # (data already scaled)
nComp <- 2
dfComponents <- predict(PCs, newdata=trainScaled)[,1:nComp]
PC_plot <- data.frame(x=dfComponents[,1], y = dfComponents[,2], col=prognosis)
colors3pal <- c("#FDAE6B", "#E6550D",  "#56B4E9")
#tsne_plot_3class <- data.frame(x=tSNEout_full$Y[,1], y = tSNEout_full$Y[,2], col=prognosis)
ggplot(PC_plot) + 
   geom_point(aes(x=x, y=y, color=as.factor(col))) + 
   ggtitle("PCA Plot of Training Data Using All Filtered Predictors of Toil Training Data") +
   xlab("PC1") + ylab("PC2") +
   scale_color_manual(name="Category",
                      breaks = c("1", "2", "3"),
                      values = c(colors3pal[1], colors3pal[2], colors3pal[3]),
                      labels = c("Healthy-GTEX", "Healthy-TCGA", "Cancer-TCGA"))
```
  
Again, the healthy samples partition well from the tumors.  And again, GTEX-healthy and TCGA-healthy are in distict clusters, showing that a batch effect still persists.  However, not addressing the batch effect allows us to either (a) keep the test set entirely separated from the training set through this entire procedure (one the data are split in step 1 above) or (b) process a single test sample without using other test samples for normalization.  

### Relative Importance of Principal Components
Let's look at the fraction of overall variance explained by each of the principal components:
```{r}
# shouldn't this be done at the level of the predictors?  (the genes)  this is all sample-based right now!

names(PCs)
df02 <- data.frame(idx=numeric(), cumVar=numeric())
for(idx in 1:length(PCs$sdev)){
   df02 <- rbind(df02, cbind(idx, cumVar=sum(I(PCs$sdev[1:idx])^2) / sum(I(PCs$sdev)^2)))
}
ggplot(df02, aes(x=idx, y=cumVar)) +
   geom_point() + ylim(0,1) + xlab("Principal Component") + ylab("Cumulative Variance") +
   theme_bw()
```
# Identifying Other PCs that Separate Healthy / Tumor
```{r, fig.height=10, fig.width=8}
plotPCs <- function(dfComponents, compIdx){
   PC_plot <- data.frame(x=dfComponents[,compIdx[1]], y = dfComponents[,compIdx[2]], col=prognosis)
   colors3pal <- c("#FDAE6B", "#E6550D",  "#56B4E9")
   #tsne_plot_3class <- data.frame(x=tSNEout_full$Y[,1], y = tSNEout_full$Y[,2], col=prognosis)
   obj <<- ggplot(PC_plot) + 
      geom_point(aes(x=x, y=y, color=as.factor(col))) + 
      ggtitle("PCA Plot of Training Data Using All Filtered Predictors of Toil Training Data") +
      xlab(paste0("PC",compIdx[1])) + ylab(paste0("PC", compIdx[2])) +
      scale_color_manual(name="Category",
                         breaks = c("1", "2", "3"),
                         values = c(colors3pal[1], colors3pal[2], colors3pal[3]),
                         labels = c("Healthy-GTEX", "Healthy-TCGA", "Cancer-TCGA"));
   return(obj)
}

plotPCs_1d <- function(dfComponents){
   PC_plot <- data.frame(x=dfComponents$Var2, y = dfComponents$value, col=prognosis)
   colors3pal <- c("#FDAE6B", "#E6550D",  "#56B4E9")
   #tsne_plot_3class <- data.frame(x=tSNEout_full$Y[,1], y = tSNEout_full$Y[,2], col=prognosis)
   obj <- ggplot(PC_plot) + 
      geom_jitter(aes(x=x, y=y, color=as.factor(col))) + 
      ggtitle("Separation of Healthy / Tumors by First Few PC's") +
      xlab("PC Number") + ylab("PC Projection") +
      theme_bw() +
      scale_color_manual(name="Category",
                         breaks = c("1", "2", "3"),
                         values = c(colors3pal[1], colors3pal[2], colors3pal[3]),
                         labels = c("Healthy-GTEX", "Healthy-TCGA", "Cancer-TCGA"));
   return(obj)
}

# define first 4 PC's:
trainScaled <- scaleData(toilTrainFiltScaled, TRUE, FALSE)
PCs <- prcomp(trainScaled)                               # (data already scaled)
nComp <- 5
dfComponents <- predict(PCs, newdata=trainScaled)[,1:nComp]
ls <- list()
pairs <- combn(5,2)
for(idx in 1:dim(pairs)[2]){
   print(idx)
   pair <- pairs[,idx]
   ls[[idx]] <- plotPCs(dfComponents, pair)
}
grid.arrange(ls[[1]], ls[[2]], ls[[3]], ls[[4]], ls[[5]], ls[[6]],
             ls[[7]], ls[[8]], ls[[9]], ls[[10]], ncol=2)
```

```{r, fig.height=6, fig.width=6}
# now let's do 1D plots of each PC:
# I will melt dfComponents and add an extra factor column which is PC_ID
require(reshape2)
dfCompMelt <- melt(dfComponents)

plotPCs_1d(dfCompMelt)
```

### Logistic Regression with Lasso Regularizer on Toil Data
I'd like to compare the performance on this breast cancer dataset in the absence of batch normalization (ComBat).
```{r, fig.height=8, fig.width=8}
###############
### Fitting Logistic Regression with Lasso Regularizer on toilSubNatural matrix
require(glmnet);
require(ggplot2);
# install_github("ririzarr/rafalib")
require(rafalib);

# scale each gene by its standard deviation and center it by its mean so that all coefficients
# are on equal footing
toilTrainFiltScaledSD <- scaleData(toilTrainFiltScaled, TRUE, FALSE)
set.seed(1011)
fitToil.lasso <- glmnet(toilTrainFiltScaledSD, outcomeTrain, family="binomial",
                           alpha = 1)
plot(fitToil.lasso, xvar="lambda", label=TRUE)

```
It's clear that scaling the predictors before Lasso enables many more to be used.  It would be interesting to see how many of these genes have a low level of expression (and therefore might be noisy data).

### Cross-Validating the Model to Pick the Smallest, Well-Performing Model
I'm going to look at cross-validating the model in order to pick the simplest one that performs well.
```{r, fig.height=8, fig.width=8}
set.seed(1011)
cv.Toil.lasso <- cv.glmnet(toilTrainFiltScaledSD, outcomeTrain, family="binomial", alpha=1) 
                      #type.measure = "deviance")
plot(cv.Toil.lasso)
```
We can see that 42 predictors gives us a model whose deviance is within 1-standard deviation from the minimum.  

### Select the Model by Capturing the Coefficients
```{r}
require(biomaRt)
coefsToil <- coef(fitToil.lasso, s=cv.Toil.lasso$lambda.1se)
allCoefsNames <- rownames(coefsToil)
idx <- which(coefsToil!= 0)
coefsFullNames <- allCoefsNames[idx]                     # USED EXTENSIVELY BELOW

coefsToilNonZero <- coefsToil[which(coefsToil!= 0)]
#class(coefsToilNonZero)                 #### get to sort numerically based on abs value, desc
coefsToilNZ_Abs <- abs(coefsToilNonZero)
coefsShortNames <- gsub("\\..*$", "", coefsFullNames)
# get Entrez ID ########################################## need for Panther

coefsDF <- data.frame(cbind(coefsToilNonZero, coefsToilNZ_Abs))
coefsDF <- cbind(coefsShortNames, coefsDF)
colnames(coefsDF) <- c("hgnc_symbol", "coefs", "coefs_abs")
genes42coef <- coefsDF %>% dplyr::arrange(desc(coefs_abs))  #%>% dplyr::select(hgnc_symbol, coefs)              
```
### Retrieving Gene Information for the Model's Predictors
These are the 42 gene predictors in the model plus the Intercept, each with its coefficient after shrinkage.
```{r, include=FALSE}
# This section records various biomaRt fields that might be useful to query.
# While there was GO cellular location, I did not find GO MF or BP.
# biomaRt FILTERS:
# listFilters(ensembl)                     # for viewing all avail filters
# with_goslim_goa	With GOSlim GOA ID(s)		
# with_hgnc	With HGNC Symbol ID(s)
# with_ens_lrg_gene	With LRG display in Ensembl gene ID(s)		
# with_ens_lrg_transcript	With LRG display in Ensembl transcript ID(s)
# ensembl_gene_id	Gene stable ID(s) [e.g. ENSG00000000003]		
# ensembl_gene_id_version	Gene stable ID(s) with version [e.g. ENSG00000000003.15]
# go	GO ID(s) [e.g. GO:0000002]
# goslim_goa	GOSlim GOA ID(s) [e.g. GO:0000003]		
# hgnc_id	HGNC ID(s) [e.g. HGNC:100]		
# hgnc_symbol	HGNC symbol(s) [e.g. A1BG]
# go_parent_term	Parent term accession
# go_parent_name	Parent term name

# biomaRt attributes: 
# attributes = listAttributes(ensembl)  # for viewing avail attributes
# description	Gene description
# gene_biotype	Gene type
# name_1006	GO term name
# goslim_goa_accession	GOSlim GOA Accession(s)	feature_page		
# goslim_goa_description	GOSlim GOA Description
# hgnc_id	HGNC ID	feature_page		
# hgnc_symbol	HGNC symbol
# entrezgene_description	NCBI gene description	feature_page		
# entrezgene_accession	NCBI gene accession	feature_page		
# entrezgene_id	NCBI gene ID
# family_description	Ensembl Family Description
```

```{r}
# we'll grab biomaRt data for these genes
listMarts()
ensembl=useMart("ensembl")
ensembl = useDataset("hsapiens_gene_ensembl",mart=ensembl)

geneNames = c("MIR497HG","BGN","SRP9","ARHGAP20","PAFAH1B3","FXYD1","NDRG2","KLHL29","SRPX","TBL2","RILP","LMOD1","KCNJ2","AC093609","RP5","TRBV11","MAZ","CNTNAP3P2","TINAGL1","CHPF2","NKAPL","LIMK1","SLC17A7","FNDC1","CDK5","ZNF668","EDNRB","SDPR","USP44","CLDN8","TTYH3","H3F3A","GABARAPL1","ABCA5","ABCG1","PDK4","KLF15","NTNG2","ATP6V0B","CTD","ADAMTS5","FAM89B")

# This code is only performed the first time:
if(FALSE){
   geneID_Name_Description <- getBM(attributes=c("hgnc_id", "hgnc_symbol", "description"),
      values=geneNames,
      mart=ensembl)
write.csv(geneID_Name_Description, file="geneAttr.csv")
}

# in subsequent runs, the attributes can be read from the file:
geneID_Name_Description <- read.csv("geneAttr.csv", header=TRUE)

# sum(geneID_Name_Description$hgnc_symbol %in% geneNames)
# geneAnnot37 <- geneID_Name_Description %>% filter(hgnc_symbol %in% geneNames)
#geneAnnot37 <- geneID_Name_Description %>% filter(hgnc_symbol %in% genes42coef$geneName)
#geneAnnot37$hgnc_id <- gsub("^HGNC:","", geneAnnot37$hgnc_id)
#missing <- setdiff(geneNames, geneAnnot37$hgnc_symbol)   # 5 genes missing from biomaRt

# grab the gene symbol and description, add coefs, clean description, and print
#geneDescrip <- geneAnnot37 %>% dplyr::select(hgnc_symbol, description)

# test
coefGeneDescrip <- inner_join(geneID_Name_Description, genes42coef, by=c("hgnc_symbol", "hgnc_symbol")) %>%
   arrange(desc(coefs_abs)) %>%
   dplyr::select(coefs, hgnc_symbol, description)
coefGeneDescrip$description <- gsub(" \\[Source.*$","", coefGeneDescrip$description)
coefGeneDescrip
```
```{r, include=FALSE}
# the following code is to bring in GO functions, but I'm not going to incorporate
# that for the moment.
if(FALSE){
   # read in GO file for functions
   # these data were obtained from ftp://ftp.pantherdb.org/sequence_classifications/current_release/PANTHER_Sequence_Classification_files/ and from there, I selected the human file.
   GO_df <- read.csv("PTHR14.1_human_", sep="\t")
   # colnames(GO_df)  # need col #1, #5, #7 
   # reduce size of GO_df
   GO_df <- GO_df[,c(1,5,7)]
   GO_df[,1] <- gsub("HUMAN\\|HGNC=", "", GO_df[,1]) %>% {gsub("\\|UniProt.*$", "", .)}
   colnames(GO_df) <- c("hgnc_id", "subfamily", "BP")
   # join the 2 df together
   geneAnnot37_Expand <- inner_join(geneAnnot37, GO_df, by=c("hgnc_id", "hgnc_id"))
   geneAnnot37_Expand$description <- gsub(" \\[Source.*$","",geneAnnot37_Expand$description)
   write.csv(geneAnnot37_Expand, "geneAttr_Expand.csv")  # pair down BP manually
   geneName_desc35 <- geneAnnot37_Expand %>% dplyr::select(hgnc_symbol, description)
}
### just need to order this info and keep the coefficient as well### 
```
when performing predictions, we'll need *coefsFullNames* and *coefsToilNonZero*.
Remember when looking at these Lasso-Regularized Coefficients that each predictor gene was offset by its mean and scaled by its standard deviation.  That way, lower and more highly transcribed genes are on equal footing to influence the model.

### Plotting Gene Expression Values Across Diagnosis for Predictor Genes
```{r, fig.height=4, fig.width=4}
jitterPlot3var2 <- function(df, var1, var2, var3, titl, pal){
   obj <- ggplot(df, aes(df[,var1], df[,var2]), colour=as.factor(df[,var3]))+ #as.factor() 
   geom_jitter(aes(col=as.factor(df[,var3])),size=2.0, height=0.3) +   #as.factor() needed
      scale_color_manual(name="Category",
                      breaks = c("1", "2", "3"),
                      values = pal,
                      labels = c("Healthy-GTEX", "Healthy-TCGA", "Cancer-TCGA")) +
   ggtitle(titl) + xlab(var1) + ylab(var2)
   theme(plot.title = element_text(size = 8, hjust=0.5)) +
   theme(axis.title = element_text(size = 6, hjust=0.5));
   return(obj)
}

predictors42scaled <- toilTrainFiltScaledSD[,colnames(toilTrainFiltScaledSD) %in% coefsFullNames]

sampleNames <- rownames(predictors42scaled)
c3vect <- c(rep(0, length(sampleNames)))
c3vect <- grepl("^GTEX", sampleNames) + c3vect
c3vect <- c3vect + 2*(grepl("^TCGA", sampleNames) &
                      grepl("\\.11$", sampleNames, perl=TRUE))
c3vect <- c3vect + 3*(grepl("^TCGA", sampleNames) &
                      grepl("\\.01$", sampleNames, perl=TRUE))

geneNames <- colnames(predictors42scaled)

ls <- list()
predictorsCorrPC2 <- c(6,8,9,15,21,22,40,42)
for(i in predictorsCorrPC2){
   geneValues <- cbind(c(rep(0, 139), rep(1, 148)), predictors42scaled[i,], c3vect)
   colnames(geneValues) <- c("diagnosis", "normalized_counts", "class")
   ls[[i]] <- jitterPlot3var2(data.frame(geneValues), "diagnosis", 
                  "normalized_counts", "class", geneNames[i], colors3pal)
}
grid.arrange(ls[[1]], ls[[2]], ls[[3]], ls[[4]], ls[[5]], ls[[6]],  # printing bug
             ls[[7]], ls[[8]], ncol=2)
```
### Plotting PC2 vs Predictors
As it appears that PC2 separates healthy / tumor samples better than PC1, I'll plot a few important predictors against PC2
```{r, fig.height=56, fig.width=8}
colors3pal <- c("#FDAE6B", "#E6550D",  "#56B4E9")
predictors42scaled <- toilTrainFiltScaledSD[,colnames(toilTrainFiltScaledSD) %in% coefsFullNames]
sampleNames <- rownames(predictors42scaled)
geneNames <- colnames(predictors42scaled)
ls <- list()
for(i in 1:42){
   PC_vs_Predictors <- data.frame(x = dfComponents[,2], y = predictors42scaled[,i],col=prognosis)
   correlation <- cor(PC_vs_Predictors$x, PC_vs_Predictors$y)
   ls[[i]] <- (ggplot(PC_vs_Predictors) + 
      geom_point(aes(x=x, y=y, color=as.factor(col))) + 
      ggtitle(paste0("Plotting ",geneNames[i]," against PC2 with CORR = ", correlation)) +
      xlab("PC2") + ylab(geneNames[i]) +
      scale_color_manual(name="Category",
                         breaks = c("1", "2", "3"),
                         values = c(colors3pal[1], colors3pal[2], colors3pal[3]),
                         labels = c("Healthy-GTEX", "Healthy-TCGA", "Cancer-TCGA")));
}
grid.arrange(ls[[1]], ls[[2]], ls[[3]], ls[[4]], ls[[5]], ls[[6]],
             ls[[7]], ls[[8]], ls[[9]], ls[[10]], ls[[11]], ls[[12]],
             ls[[13]], ls[[14]], ls[[15]], ls[[16]], ls[[17]], ls[[18]],
             ls[[19]], ls[[20]], ls[[21]], ls[[22]], ls[[23]], ls[[24]],
             ls[[25]], ls[[26]], ls[[27]], ls[[28]], ls[[29]], ls[[30]],
             ls[[31]], ls[[32]], ls[[33]], ls[[34]], ls[[35]], ls[[36]],
             ls[[37]], ls[[38]], ls[[39]], ls[[40]], ls[[41]], ls[[42]],
             ncol=2)
```
### Printing Samples Across Predictors in Line Graph
This graph will demonstrate that although the individual predictors have essentially identical behavior between the healthy samples and tumors, I believe that when samples are plotted across the 42 predictors that we'll see a separation between healthy samples and tumors.
```{r, fig.height=6, fig.width=10, dpi=300}
require(reshape2)
# need to shorten names and print those gene names vertically
colnames(predictors42scaled) <- coefsShortNames[2:length(coefsShortNames)]  # simplify predictor names
colors3pal <- c("#FDAE6B", "#E6550D",  "#56B4E9")
predict42scaledMelt <- melt(predictors42scaled)
predict42scaledMelt <- cbind(predict42scaledMelt , colr=as.factor(rep(prognosis, 42)))
ggplot(predict42scaledMelt, aes(x=Var2, y=value)) + #, colour=colr)) +
   geom_jitter(aes(colour=colr)) +
   ylim(-2,5) + theme(axis.text.x=element_text(angle=90)) +
   scale_color_manual(name="Category",
                         breaks = c("1", "2", "3"),
                         values = c(colors3pal[1], colors3pal[2], colors3pal[3]),
                         labels = c("Healthy-GTEX", "Healthy-TCGA", "Cancer-TCGA"))

```
### Using 2 genes to separate out healthy and tumor samples
I'm going to use MIR497HG and PAFAH1B3 to create a 2D plot of the samples colored by their healthy / tumor status.  I'm choosing these two because they have large coefficients in the model and because they are inversely correlated with one another.
```{r, fig.height=4, fig.width=4}
df03 <- predictors42scaled[,c("PAFAH1B3", "MIR497HG")]
df03 <- data.frame(cbind(df03, col=as.factor(prognosis)))
ggplot(df03) +
   geom_point(aes(x=PAFAH1B3,y=MIR497HG,colour=as.factor(col))) +
    #ylim(-2,5) + #theme_bw() + # (axis.text.x=element_text(angle=90)) +
   scale_color_manual(name="Category",
                         breaks = c("1", "2", "3"),
                         values = c(colors3pal[1], colors3pal[2], colors3pal[3]),
                         labels = c("Healthy-GTEX", "Healthy-TCGA", "Cancer-TCGA"))
```
### Correlation between Predictors
```{r}
predictorDist <- dist(t(predictors42scaled))
sampleDist <- dist(predictors42scaled)
image(as.matrix(sampleDist))

```
### Heatmap of Samples and Predictor Genes
```{r, fig.height=12, fig.width=10}
require(heatmap3)
library(RColorBrewer)
require(gplots)
#hmcol <- colorRampPalette(brewer.pal(9, "GnBu"))(100)    # set coloring heat map
samples <- factor(prognosis)
#cols <- palette(brewer.pal(1, "Set1"))[samples]         # set color of sample class
sampleCols <- palette(colors3pal)[samples]         # set color of sample class
# narrow range for color dynamic range
# c("#40004B", "#762A83", "#9970AB", "#C2A5CF", "#E7D4E8", 
#   "#F7F7F7", 
#   "#D9F0D3","#A6DBA0", "#5AAE61", "#1B7837", "#00441B")
# hmcol <- colorRampPalette(c("#40004B", "#40004B", "#762A83", "#9970AB", "#C2A5CF",
#   "#F7F7F7",
#   "#A6DBA0", "#5AAE61", "#1B7837", "#00441B", "#00441B"))
hmcol <- colorRampPalette(c("#40004B", "#40004B", "#40004B", "#762A83", "#9970AB", 
  "#F7F7F7",
  "#5AAE61", "#1B7837", "#00441B", "#00441B", "#00441B"))
# colorVals <- c(-15,-3,-2.5,-2,-1.5,-1,-0.5,0,0.5,1,1.5,2,2.5,3,15)
# hmcol <- colorRampPalette(c("lightblue", "blue"))[colorVals]
#hmcol <- colorRampPalette(brewer.pal(11, "PRGn"))
heatmap.2(as.matrix(predictors42scaled), col=hmcol, trace="none", cexRow = 0.15, cexCol = 0.5,  RowSideColors = sampleCols, main = "Heatmap of Gene Predictors vs Samples")
# ColSideColors = cols,
# heatmap(as.matrix(predictors42scaled))  # figure margins too large
```
### Filter and Scale Test Data.  (A) Relying on Training Data for Zero-Filtering and Scaling of Test Data
```{r}
### 1. Filter out near-zero genes as defined with training data:

## zero Filtering Must be re-indexed for test set
toilToFilterPosn <- which(colnames(toilTest) %in% names(ZEROEXPGENES))
toilTestFilter <- toilTest[,-toilToFilterPosn] # using Same Gene List Filter (near-zero) established in Training Set
# now 95 x 32177 on log2(x+1) scale


### 2. Scale test data as fraction of all sample counts
## define scaling function (same logic as with training data)
toilTestFiltNat <- 2^(toilTestFilter) - 1

scaleTestSamples <- function(X, logged=FALSE){  # X is matrix with samples as rows
                   # representative reference sample selected via edgeR specs
                   # this script assumes data are on natural scale.
   Xnat <- if(logged==TRUE) ((2^X)-1) else X  # put in natural scale
   N <- apply(Xnat, 1, sum)
   scaledX <- apply(Xnat, 2, function(x) x / N)
   return(scaledX)
}
toilTestScaled <- scaleTestSamples(toilTestFiltNat, logged=FALSE)


### 3. Individually scale test samples relative to training reference sample.  
# Each scaling is independent of other scalings.
# There is a filtering step (subsetCommonPredictors) that is applied first, 
# as we're using some of the references from the training set for the test set.

# subsetCommonPredictors <- function(refSmp, tstSmp, coefsFullNames){
#    
#    # AT this point, I've moved the common genes upstream
#    # the only thing that's happening here is that the (Intercept) is being 
#    # removed from the RefSample.
#    
#    commonNames = intersect(names(refSmp), names(tstSmp))
#    # need to add back any missing predictors
#    commonNamesPlus <- sort(unique(append(commonNames, coefsFullNames)))
#    print(c("commonQA", length(commonNames), length(commonNamesPlus)))
#    refUniqNames <- setdiff(names(refSmp), commonNamesPlus)
#    refUniqPosn <- which(names(refSmp) %in% refUniqNames)
# 
#    tstUniqNames <- setdiff(names(tstSmp), commonNamesPlus)
#    tstUniqPosn <- which(names(tstSmp) %in% tstUniqNames)
#    print(c("Other", refUniqPosn,tstUniqPosn))
#    print(c("final Lengths", length(refSmp[-refUniqPosn]), length(tstSmp[-tstUniqPosn])))
#    return(list(refSmp[-refUniqPosn], tstSmp[-tstUniqPosn]))
# } # I am losing some critical predictors at this stage


ScalFact <- list()
samples <- rownames(toilTestFilter)

## Are the coefficients already missing here?  -- YES.
# toilTest has them all
# toilTestScaled and Filter missing many
#which(colnames(toilTestFilter) %in% coefsFullNames[2:length(coefsFullNames)])



i <- 1
for(testSampleName in samples){  # some of the passed variables were created in training set
   testSample <- toilTestScaled[i,]
   testUnscaled <- toilTestFiltNat[i,]
   
   # ensure that intersection of genes the same across 4 lists
   #v <- subsetCommonPredictors(refSample, testSample, coefsFullNames)
   #refSample2 <- v[[1]]
   #testSample2 <- v[[2]]
   refSample2 <- REFSAMPLE[2:length(REFSAMPLE)]
   testSample2 <- testSample[names(refSample2)]
   testUnscaled2 <- testUnscaled[names(refSample2)]
   refSampleUnscaled2 <- REFSAMPLEUNSCALED[names(refSample2)]
   #print(all(names(testUnscaled2)==names(testSample2)))
   #print(c(length(refSample2), length(testSample2), length(refSampleUnscaled2),
           #   length(testUnscaled2)))
   
   scalingFactor <- weightedTrimmedMean(refSample2, testSample2, REFNAME, testSampleName,
                                        testUnscaled2, refSampleUnscaled2)
   ScalFact <- c(ScalFact, scalingFactor)
   i = i+1
}
ScalFact <- unlist(ScalFact)             

### 4. Scale toilTrainFilter matrix using scaling factors
# dim(toilTestFiltNat)
toilTestFiltScaled <- apply(toilTestFiltNat, 2, function(x) x/ScalFact)

### 5. scale each gene by its standard deviation and center it by its mean so that all coefficients
#      are on equal footing
#toilTestFiltScaledSD <- scaleData(toilTestFiltScaled, TRUE, FALSE)       # this would not be possible for individual samples!!!!!!
#toilTestFiltScaledSD <- cbind(rep(1,dim(toilTestFiltScaledSD)[1]), toilTestFiltScaledSD) #add intercept column
```
### 4. Remove Non-Predictor Genes from Filtered Test Data
We're just keeping the 42 predictors from toilTestFiltScaled
```{r}
colIDs <- which(colnames(toilTestFiltScaled) %in% coefsFullNames[2:length(coefsFullNames)])
toilTestFiltScal42 <- toilTestFiltScaled[,colIDs]
```
### 5. Each Relevant Predictor Gene offset by Its Mean and Scaled by Its Standard Deviation
```{r}
# colnames(toilTestFiltScal42)
toilTestFiltScaledSD <- scaleData(toilTestFiltScal42, TRUE, FALSE)       
# this would not be possible for individual samples!!!!!!
toilTestFiltScaledSD <- cbind(rep(1,dim(toilTestFiltScaledSD)[1]), toilTestFiltScaledSD)
```
### Create Confusion Matrix for Test Data

```{r}
testPredictions_toil <- ifelse(toilTestFiltScaledSD %*% coefsToilNonZero > 0, 1, 0)
table(outcomeTest, testPredictions_toil)
```
I am seeing 100% specificity and 100% specificity!

### Filter and Scale Test Data.  (B) Not Relying on Training Data for Zero-Filtering or Scaling of Test Data
In order to see if the test data predictions might be biased by filtering relative to a list of genes identified using only training data or by scaling relative to a training reference sample, I'll repeat the process here, but using only *test data*.  In order to achieve this, when the predictions are made, we must only use predictors with non-zero coefficients, or the linear algebra will fail.

### 1. Filter Out Genes Whose Expression is Near-Zero 
```{r}
# next, let's filter all 3rd quartile < 0.14 counts--filter criterion in log-scale:
toilTestNat <- (2^toilTest)-1    # natural scale
# next, let's filter all 3rd quartile < 0.14 counts--filter criterion in log-scale:
zeroExpGenes <- which(apply(toilTest, 2, function(x) quantile(x)[4]) < 0.2)    #USED LATER
toilTestFilter <- toilTestNat[,-zeroExpGenes]
#quart3 <- apply(toilTestFilter, 1, function(x) quantile(x)[4])
#sd(quart3)/mean(quart3)              # CV drops slightly to 0.336
#hist(log2(quart3 + 1))
```
### 2. Select a Reference Sample Amongst Test Samples for Scaling Data
```{r}
lst <- pickRefSample(toilTestFilter, logged=FALSE) 
testRefName <- lst[[1]]                                                        
toilTestScaled <- lst[[2]]
testRefSample <- toilTestScaled[which(rownames(toilTestScaled) == testRefName),]  
testRefSampleUnscaled <- toilTestFilter[testRefName,]                              
print(paste0("The sample chosen to the the Reference Sample for the purposes of Sample-to-Sample Normalization is ",
        testRefName, "."))
```
### 3. Scaling Test Samples Relative to the Chosen TEST Reference Sample (Sample-to-Sample Normalization)

```{r}
ScalFact <- list()
samples <- rownames(toilTestFilter)
i <- 1
for(testSampleName in samples){
   testSample <- toilTestScaled[i,]
   testUnscaled <- toilTestFilter[i,]
   scalingFactor <- weightedTrimmedMean(testRefSample, testSample, testRefName, testSampleName, testUnscaled,
                                        testRefSampleUnscaled)    
   ScalFact <- c(ScalFact, scalingFactor)
   i = i+1
}
ScalFact <- unlist(ScalFact)

### Scale toilTrainFilter matrix using scaling factors
# dim(toilTestFilter)
toilTestFiltScaled <- apply(toilTestFilter, 2, function(x) x/ScalFact)
### we now have a scaled test matrix
```
### 4. Remove Non-Predictor Genes from Filtered Test Data
We're just keeping the 42 predictors from toilTestFiltScaled
```{r}
toilTestFiltScal42 <- toilTestFiltScaled[,coefsFullNames[2:length(coefsFullNames)]]
```
### 5. Each Relevant Predictor Gene offset by Its Mean and Scaled by Its Standard Deviation
```{r}
toilTestFiltScaledSD <- scaleData(toilTestFiltScal42, TRUE, FALSE)       
# this would not be possible for individual samples!!!!!!
toilTestFiltScaledSD <- cbind(rep(1,dim(toilTestFiltScaledSD)[1]), toilTestFiltScaledSD)
```
### Create Confusion Matrix for Test Data

```{r}
testPredictions_toil <- ifelse(toilTestFiltScaledSD %*% coefsToilNonZero > 0, 1, 0)
table(outcomeTest, testPredictions_toil)
```
I am still at 100% sensitivity and 100% specificity!  I used no training data for filtering or scaling the test samples.  The test set was treated separately from the beginning.

### Test Model Accuracy on TCGA Data Not Yet Examined  
At this point, we've exhausted all the healthy breast samples either in the training set or the test set.  
However, I'd like to test this model across the remaining TCGA tumors, grouped by *tumor stage* to see how well the model performs on those samples.  

##### Collecting Unused TCGA Samples, Grouped by Tumor Stage
I'll grab all TCGA sample names, remove those that have already been used in this study,
either as training or test samples, and then group the data by tumor stage.  
*I am not limiting this set to the Wang subset*
```{r}
require(BBmisc)
# read in TCGA attribute file:
TCGA_Attr_Full <- read.csv("~/Desktop/Tresorit_iOS/projects/RNA-Seq/data/TCGA_Attributes_full.txt",
         header=TRUE, sep="\t", stringsAsFactors = FALSE)
TCGA_ID_Stage <- TCGA_Attr_Full %>% dplyr::select(tcgaID, tumor_stage)
rm(TCGA_Attr_Full)

# grab all TCGA IDs already used--already created as wangTCGAsamples
# there's also a toilSampleNames object as well.  # NOTE THAT FINAL LETTER STRIPPED OFF

# initialize six tumor stage dataframes
stageOne <- data.frame(tcgaID=character(), stage=character(), novel=character())
stageTwo <- data.frame(tcgaID=character(), stage=character(), novel=character())
stageThree <- data.frame(tcgaID=character(), stage=character(), novel=character())
stageFour <- data.frame(tcgaID=character(), stage=character(), novel=character())
stageZero <- data.frame(tcgaID=character(), stage=character(), novel=character())
stageHealthy <- data.frame(tcgaID=character(), stage=character())
stageUnknown <- data.frame(tcgaID=character(), stage=character())

######################################
# function for appending to dataframes
appendDFtumor <- function(id, stage){  # appends non-healthy smpl/df
   if(any(grepl(gsub("[ABZ]$","",id), wangTCGAsamples))){
      vect <- cbind(id, stage, novel="already_used")}  # need to eval df
   else{
      vect <- cbind(id, stage, novel="unused")}
   return(vect)
}
#######################################
#######################################
# break apart tcgaIDs, and classify by type (converted to factor)
processTumorStage <- function(df){  #expects  1 row of 2 col df: 
                                    # tcga_ID and tumor_stage
   
   stage = unlist(df[2])
   for(id in unlist(strsplit(df[1], ";"))){
      if(grepl("10[ABZ]$", id) | grepl("11[ABZ]", id)){  # filter our healthy samples  --- BACKWARDS 01 is cancer!
         #stageHealthy <<- rbind(stageHealthy, cbind(id, "healthy"))
         stageHealthy <<- rbind(stageHealthy, appendDFtumor(id, stage="healthy"))
      }
      else{    
         if(grepl("stage i[ab]", stage) | grepl("stage i$", stage)){
            stageOne <<- rbind(stageOne, appendDFtumor(id, stage))}
         else if(grepl("stage ii[ab]", stage) | grepl("stage ii$", stage)){
            stageTwo <<- rbind(stageTwo, appendDFtumor(id, stage))}
         else if(grepl("stage iii[abc]", stage) | grepl("stage iii$", stage)){
            stageThree <<- rbind(stageThree, appendDFtumor(id, stage))}
         else if(grepl("stage iv[ab]", stage) | grepl("stage iv$", stage)){
            stageFour <<- rbind(stageFour, appendDFtumor(id, stage))}
         else if(grepl("stage x", stage) | grepl("not reported", stage)){
            stageUnknown <<- rbind(stageUnknown, cbind(id, stage))}
         else{
             # print(c(id, stage, "missing class")) # all accounted for
         }
      }
   }
}
########################################


apply(TCGA_ID_Stage, 1, processTumorStage)      # WARNING--there is an amplification due to last-letter
# rownames very ugly and not helpful!

# some code determining if there is more than 1 sample per class from 1 individual

# read huge TCGA file in, then for each stage of "unused" rows, grab the 
# file of data, create new dataframe, and save to disk for future use
# also convert TCGA IDs using dots (.) rather than dashes(-)
# BUGS in this section now fixed.
toilData <- read.table("/Users/mjk/RNA-Seq_2019/TOIL_Data/TcgaTargetGtex_gene_expected_count", 
                       header=TRUE, stringsAsFactors = FALSE)
toilSampleNames <- as.character(colnames(toilData))

stageOneIDs <- (stageOne %>% dplyr::filter(novel=="unused") %>% dplyr::select(id) %>% 
                convertColsToList())[[1]] %>% {gsub("[ABZC]$", "", .)} %>%      
   {gsub("-", "\\.", .)} %>% unique()   # 153 long

stageTwoIDs <- (stageTwo %>% dplyr::filter(novel=="unused") %>% dplyr::select(id) %>% 
                convertColsToList())[[1]] %>% {gsub("[ABZC]$", "", .)} %>% 
   {gsub("-", "\\.", .)} %>% unique()   # 523 long

stageThreeIDs <- (stageThree %>% dplyr::filter(novel=="unused") %>% dplyr::select(id) %>% 
                convertColsToList())[[1]] %>% {gsub("[ABZC]$", "", .)} %>% 
   {gsub("-", "\\.", .)} %>% unique()   # 203 long

stageFourIDs <- (stageFour %>% dplyr::filter(novel=="unused") %>% dplyr::select(id) %>% 
                convertColsToList())[[1]] %>% {gsub("[ABZC]$", "", .)} %>% 
   {gsub("-", "\\.", .)} %>% unique()   # 20 long

stageHealthyIDs <- (stageHealthy %>% dplyr::filter(novel=="unused") %>% dplyr::select(id) %>% 
                convertColsToList())[[1]] %>% {gsub("[ABZC]$", "", .)} %>% 
   {gsub("-", "\\.", .)} %>% unique()   # 1052 long ??????


### Now grab the actual data, now that we've separated tumors by stage and filtered out
### training samples and early-used test samples:
### I'm also transposing the dataframes here as well:
stageOneDF <- t(toilData[,which(toilSampleNames %in% stageOneIDs)])          # 147 smpls
stageTwoDF <- t(toilData[,which(toilSampleNames %in% stageTwoIDs)])          # 514
stageThreeDF <- t(toilData[,which(toilSampleNames %in% stageThreeIDs)])      # 203
stageFourDF <- t(toilData[,which(toilSampleNames %in% stageFourIDs)])        #  20
stageHealthyDF <- t(toilData[,which(toilSampleNames %in% stageHealthyIDs)])  #   4 --most not in TOIL

### add gene names, as done above:
colnames(stageOneDF) <- colnames(toilTrainNat)
colnames(stageTwoDF) <- colnames(toilTrainNat)
colnames(stageThreeDF) <- colnames(toilTrainNat)
colnames(stageFourDF) <- colnames(toilTrainNat)
colnames(stageHealthyDF) <- colnames(toilTrainNat)


# now write these DF to files for future use!
write.table(stageOneDF, "stageOneTest.txt", sep="\t", row.names = TRUE)
write.table(stageTwoDF, "stageTwoTest.txt", sep="\t", row.names = TRUE)
write.table(stageThreeDF, "stageThreeTest.txt", sep="\t", row.names = TRUE)
write.table(stageFourDF, "stageFourTest.txt", sep="\t", row.names = TRUE)
write.table(stageHealthyDF, "stageHealthyTest.txt", sep="\t", row.names = TRUE)

################################################## comment out lines of code above.

stageOneDF <- read.csv("stageOneTest.txt", header=TRUE, sep="\t",
           stringsAsFactors = FALSE)
# REPEAT


# Next: filter, normalize, etc. Perform all-test groups separately from one another
# and separately from training set.

# create outcome vectors for each test dataset
stageOneOutcome <- rep(1,dim(stageOneDF)[1])
stageTwoOutcome <- rep(1,dim(stageTwoDF)[1])
stageThreeOutcome <- rep(1,dim(stageThreeDF)[1])
stageFourOutcome <- rep(1,dim(stageFourDF)[1])
stageHealthyOutcome <- rep(0,dim(stageHealthyDF)[1])
```

### 1. Filter Out Genes Whose Expression is Near-Zero 
```{r}
# next, let's filter all 3rd quartile < 0.14 counts--filter criterion in log-scale:
stageOneNat <- (2^stageOneDF)-1    # natural scale
zeroExpGenes <- which(apply(stageOneDF, 2, function(x) quantile(x)[4]) < 0.2)    
stageOneFilter <- stageOneNat[,-zeroExpGenes]

stageTwoNat <- (2^stageTwoDF)-1    # natural scale
zeroExpGenes <- which(apply(stageTwoDF, 2, function(x) quantile(x)[4]) < 0.2)    
stageTwoFilter <- stageTwoNat[,-zeroExpGenes]

stageThreeNat <- (2^stageThreeDF)-1    # natural scale
zeroExpGenes <- which(apply(stageThreeDF, 2, function(x) quantile(x)[4]) < 0.2)    
stageThreeFilter <- stageThreeNat[,-zeroExpGenes]

stageFourNat <- (2^stageFourDF)-1    # natural scale
zeroExpGenes <- which(apply(stageFourDF, 2, function(x) quantile(x)[4]) < 0.2)    
stageFourFilter <- stageFourNat[,-zeroExpGenes]

stageHealthyNat <- (2^stageHealthyDF)-1    # natural scale
zeroExpGenes <- which(apply(stageHealthyDF, 2, function(x) quantile(x)[4]) < 0.2)    
stageHealthyFilter <- stageHealthyNat[,-zeroExpGenes]
```
### 2. Select a Reference Sample Amongst Test Samples for Scaling Data
```{r}
# lst <- pickRefSample(stageOneFilter, logged=FALSE) 
# stageOneRefName <- lst[[1]]                                                        
# stageOneFraction <- lst[[2]]         # scaling = x is fraction of all cts across sample
# stageOneRefSample <- stageOneFraction[which(rownames(stageOneFraction) == stageOneRefName),]  
# stageOneRefSampleUnscaled <- stageOneFilter[stageOneRefName,]                              
# print(paste0("The sample chosen to the the Reference Sample for the purposes of Sample-to-Sample Normalization is ",
#         stageOneRefName, "."))
################################
# replace with generic function:
refSampleWrapper <- function(dfFilter){
   lst <- pickRefSample(dfFilter, logged=FALSE) 
   refName <- lst[[1]]                                                        
   dfFraction <- lst[[2]]   # all x now fraction of total cts per sample
   refSample <- dfFraction[which(rownames(dfFraction) == refName),]  
   refSampleUnscaled <- dfFilter[refName,]                              
   print(paste0("The sample chosen to the the Reference Sample for the purposes of Sample-to-Sample Normalization is ",
           refName, "."))
   return(list(refName, dfFraction, refSample, refSampleUnscaled))
}
###############################
retVector <- refSampleWrapper(stageOneFilter)
stageOneRefName = retVector[[1]]           # re-write whole thing using objects later
stageOneFraction = retVector[[2]]
stageOneRefSample = retVector[[3]]
stageOneRefSampleUnscaled = retVector[[4]]

retVector <- refSampleWrapper(stageTwoFilter)
stageTwoRefName = retVector[[1]]           # re-write whole thing using objects later
stageTwoFraction = retVector[[2]]
stageTwoRefSample = retVector[[3]]
stageTwoRefSampleUnscaled = retVector[[4]]

retVector <- refSampleWrapper(stageThreeFilter)
stageThreeRefName = retVector[[1]]           # re-write whole thing using objects later
stageThreeFraction = retVector[[2]]
stageThreeRefSample = retVector[[3]]
stageThreeRefSampleUnscaled = retVector[[4]]

retVector <- refSampleWrapper(stageFourFilter)
stageFourRefName = retVector[[1]]           # re-write whole thing using objects later
stageFourFraction = retVector[[2]]
stageFourRefSample = retVector[[3]]
stageFourRefSampleUnscaled = retVector[[4]]

retVector <- refSampleWrapper(stageHealthyFilter)
stageHealthyRefName = retVector[[1]]           # re-write whole thing using objects later
stageHealthyFraction = retVector[[2]]
stageHealthyRefSample = retVector[[3]]
stageHealthyRefSampleUnscaled = retVector[[4]]
```

### 3. Scaling Test Samples Relative to the Chosen TEST Reference Sample (Sample-to-Sample Normalization)

```{r}
require(ggplot2)
# The calcScalingFactors function calculates a scaling factor for each sample in
# the fraction dataframe.  It calls weightedTrimmedMean of edgeR.
calcScalingFactors <- function(dfFiltered, dfScaled, refSample, refName,
                               testRefSampleUnscaled){
   ScalFact <- list()
   samples <- rownames(dfFiltered)
   i <- 1
   for(testSampleName in samples){
      testSample <- dfScaled[i,]
      testUnscaled <- dfFiltered[i,]
      scalingFactor <- weightedTrimmedMean(refSample, testSample, refName, testSampleName, 
                                           testUnscaled,testRefSampleUnscaled)    
      ScalFact <- c(ScalFact, scalingFactor)
      i = i+1
   }
   ScalFact <- unlist(ScalFact)
   return(ScalFact)
}

stageOneSFs <- calcScalingFactors(stageOneFilter, stageOneFraction, stageOneRefSample,
                                  stageOneRefName, stageOneRefSampleUnscaled)
stageTwoSFs <- calcScalingFactors(stageTwoFilter, stageTwoFraction, stageTwoRefSample,
                                  stageTwoRefName, stageTwoRefSampleUnscaled)
stageThreeSFs <- calcScalingFactors(stageThreeFilter, stageThreeFraction, stageThreeRefSample,
                                  stageThreeRefName, stageThreeRefSampleUnscaled)
stageFourSFs <- calcScalingFactors(stageFourFilter, stageFourFraction, stageFourRefSample,
                                  stageFourRefName, stageFourRefSampleUnscaled)
stageHealthySFs <- calcScalingFactors(stageHealthyFilter, stageHealthyFraction, stageHealthyRefSample,
                                  stageHealthyRefName, stageHealthyRefSampleUnscaled)


### Scale toilTrainFilter matrix using scaling factors

stageOneFiltScaled <- apply(stageOneFilter, 2, function(x) x/stageOneSFs)
stageTwoFiltScaled <- apply(stageTwoFilter, 2, function(x) x/stageTwoSFs)
stageThreeFiltScaled <- apply(stageThreeFilter, 2, function(x) x/stageThreeSFs)
stageFourFiltScaled <- apply(stageFourFilter, 2, function(x) x/stageFourSFs)
stageHealthyFiltScaled <- apply(stageHealthyFilter, 2, function(x) x/stageHealthySFs)
### we now have a scaled test matrix
```
### 4. Remove Non-Predictor Genes from Filtered Test Data
We're just keeping the 42 predictors from toilTestFiltScaled
```{r}
stageOneFiltScal42 <- stageOneFiltScaled[,coefsFullNames[2:length(coefsFullNames)]]
stageTwoFiltScal42 <- stageTwoFiltScaled[,coefsFullNames[2:length(coefsFullNames)]]
stageThreeFiltScal42 <- stageThreeFiltScaled[,coefsFullNames[2:length(coefsFullNames)]]
stageFourFiltScal42 <- stageFourFiltScaled[,coefsFullNames[2:length(coefsFullNames)]]
stageHealthyFiltScal42 <- stageHealthyFiltScaled[,coefsFullNames[2:length(coefsFullNames)]]
```
### 5. Each Relevant Predictor Gene offset by Its Mean and Scaled by Its Standard Deviation
```{r}
# this would not be possible for individual samples!!!!!!
stageOneFiltScaledSD <- scaleData(stageOneFiltScal42, TRUE, FALSE)       
stageOneFiltScaledSD <- cbind(rep(1,dim(stageOneFiltScaledSD)[1]), stageOneFiltScaledSD) #add intercept term
stageTwoFiltScaledSD <- scaleData(stageTwoFiltScal42, TRUE, FALSE)       
stageTwoFiltScaledSD <- cbind(rep(1,dim(stageTwoFiltScaledSD)[1]), stageTwoFiltScaledSD) #add intercept term
stageThreeFiltScaledSD <- scaleData(stageThreeFiltScal42, TRUE, FALSE)       
stageThreeFiltScaledSD <- cbind(rep(1,dim(stageThreeFiltScaledSD)[1]), stageThreeFiltScaledSD) #add intercept term
stageFourFiltScaledSD <- scaleData(stageFourFiltScal42, TRUE, FALSE)       
stageFourFiltScaledSD <- cbind(rep(1,dim(stageFourFiltScaledSD)[1]), stageFourFiltScaledSD) #add intercept term
stageHealthyFiltScaledSD <- scaleData(stageHealthyFiltScal42, TRUE, FALSE)       
stageHealthyFiltScaledSD <- cbind(rep(1,dim(stageHealthyFiltScaledSD)[1]), stageHealthyFiltScaledSD) #add intercept term
```
### Create Confusion Matrix for Test Data

```{r}
testPredictions_toil <- ifelse(stageOneFiltScaledSD %*% coefsToilNonZero > 0, 1, 0)
table(stageOneOutcome, testPredictions_toil)
```
```{r}
testPredictions_toil <- ifelse(stageTwoFiltScaledSD %*% coefsToilNonZero > 0, 1, 0)
table(stageTwoOutcome, testPredictions_toil)
```
```{r}
testPredictions_toil <- ifelse(stageThreeFiltScaledSD %*% coefsToilNonZero > 0, 1, 0)
table(stageThreeOutcome, testPredictions_toil)
```
```{r}
testPredictions_toil <- ifelse(stageFourFiltScaledSD %*% coefsToilNonZero > 0, 1, 0)
table(stageFourOutcome, testPredictions_toil)
```
```{r}
testPredictions_toil <- ifelse(stageHealthyFiltScaledSD %*% coefsToilNonZero > 0, 1, 0)
table(stageHealthyOutcome, testPredictions_toil)
```
As we can see, the performance is quite poor.  This could either be the result of normalizing
normal and cancer samples separately, or it could be because there's a lot of poor quality
samples that were filtered out by Wang, et. al, and while that was done at the ComBat
stage, I used the Wang sample list to filter out Toil sample up until this point.  If the issue is normalizing samples separately, then this should be fixable by just normalizing relative to the REFSAMPLE and ZEROEXPGENES that were defined at the top of this document and used in part (A) 

COULD ALSO COLOR REFERENCE SAMPLE IN TSNE AND PCA PLOTS

### Trial 1: Normalize stageThree with REFSAMPLE defined way at the top:
The REFSAMPLE obtained from the TRAINING SET, along with its associated data, as well
as the ZEROEXPGENES, those genes with virtually no expression in the TRAINING set, will be used
to normalize the "stage 3" tumor samples and healthy samples together to see if it recovers
the lost performance just seen in the TCGA set.
```{r}
# from before: ZEROEXPGENES REFNAME REFSAMPLE REFSAMPLEUNSCALED 

# 1. merge together stage 3 and healthy from TCGA:
dim(stageThreeDF)
healthy3df <- rbind(stageHealthyDF, stageThreeDF)
healthy3dfOutcome <- c(rep(0, dim(stageHealthyDF)[1]), rep(1, dim(stageThreeDF)[1]))

# 1b. convert to natural scale:
healthy3Nat <- (2^healthy3df)-1    # natural scale

# 2. subtract out ZEROEXPGENES, as defined in training set
healthy3NatFilt <- healthy3Nat[,-ZEROEXPGENES]

# 2b. represent intensities as fraction of all signals in each sample
N <- apply(healthy3NatFilt, 1, sum)
healthy3FiltFrac <- apply(healthy3NatFilt, 2, function(x) x / N)

# 3. Calculate scaling factor, relative to REFSAMPLE, for each sample in healthy3...
healthy3SFs <- calcScalingFactors(healthy3NatFilt, healthy3FiltFrac, REFSAMPLE,
                                  REFNAME, REFSAMPLEUNSCALED)

# 3b. Apply scaling factors
healthy3FiltScaled <- apply(healthy3NatFilt, 2, function(x) x/healthy3SFs)

# 4. Remove Non-Predictor Genes from Filtered Test Data, then add intercept.
# We're just keeping the 42 predictors from toilTestFiltScaled
healthy3FiltScal42 <- healthy3FiltScaled[,coefsFullNames[2:length(coefsFullNames)]]

# 5. scale each gene by its stdev and offset by its mean
healthy3FiltScaledSD <- scaleData(healthy3FiltScal42, TRUE, FALSE)       
healthy3FiltScaledSD <- cbind(rep(1,dim(healthy3FiltScaledSD)[1]), healthy3FiltScaledSD) #add intercept term

# Create Confusion Matrix for Test Data
testPredictions_toil <- ifelse(healthy3FiltScaledSD %*% coefsToilNonZero > 0, 1, 0)
table(healthy3dfOutcome, testPredictions_toil)

```
My performance is much, much better!  96% sensitivity and 100% specificity!!

#### Conclusions:  
1. From the test just performed, whatever Wang quality filtering that was done must have a minor effect (4% on sensitivity).  
2. That EITHER the *training* REFSAMPLE or the fact that tumor and normal samples were normalized together, or both, largely recovered the earlier performance.


### Trial 2: Mix healthy and stage 3 and normalize together.
Here, I'm going to try to see if the TEST samples alone (healthy and stage3) can both (a) determine the effectively-not expressed genes, (b) find their own mutual reference sample, and (c) perform well on the logist regression model with lasso regularizer.  
```{r}
# We'll start with the merged dataframe in the natural scale above:

# 1. Determine which are the genes that are essentially zero-expression in log scale:
zeroExpGenes <- which(apply(healthy3df, 2, function(x) quantile(x)[4]) < 0.2)    

# 2. subtract out ZEROEXPGENES, as defined in training set
healthy3NatFilt <- healthy3Nat[,-zeroExpGenes]
# healthy3NatFilt <- healthy3Nat[,-ZEROEXPGENES]

# 2b. represent intensities as fraction of all signals in each sample
# N <- apply(healthy3NatFilt, 1, sum)    NO, DONE AS PART OF REFSAMPLEWRAPPER
# healthy3FiltFrac <- apply(healthy3NatFilt, 2, function(x) x / N)

# 3a. Choose reference sample amongst the healthy-stage3 test dataframe samples:
retVector <- refSampleWrapper(healthy3NatFilt)
healthy3RefName = retVector[[1]]
healthy3NatFiltFrac = retVector[[2]]
healthy3RefSample = retVector[[3]]
healthy3RefSampleUnscaled = retVector[[4]]

# 3b. Calculate scaling factors for heathy3NatFilt dataframe samples:
healthy3SFs <- calcScalingFactors(healthy3NatFilt, healthy3NatFiltFrac, healthy3RefSample,
                                  healthy3RefName, healthy3RefSampleUnscaled)

# 3c. scale each sample in the healthy3NatFilt dataframe
healthy3FiltScaled <- apply(healthy3NatFilt, 2, function(x) x/healthy3SFs)

# 4. # 4. Remove Non-Predictor Genes from Filtered Test Data
healthy3FiltScal42 <- healthy3FiltScaled[,coefsFullNames[2:length(coefsFullNames)]]

# 5. scale each gene by its stdev and offset by its mean
healthy3FiltScaledSD <- scaleData(healthy3FiltScal42, TRUE, FALSE)       
healthy3FiltScaledSD <- cbind(rep(1,dim(healthy3FiltScaledSD)[1]), healthy3FiltScaledSD) #add intercept term

# Create Confusion Matrix for Test Data
testPredictions_toil <- ifelse(healthy3FiltScaledSD %*% coefsToilNonZero > 0, 1, 0)
table(healthy3dfOutcome, testPredictions_toil)
```
I get the same 96% sensitivity and 100% specificity as using the *training* REFSAMPLE and ZEROEXPGENES!
MANY OF THESE SAMPLES ARE ACTUALLY IN THE TRAINING SET!!

##### Conclusion:  
It appears that the essential part is that I have a mixture of healthy and tumors when going through the filtering, scaling and normalization steps (or at least one of them).  That does not rule out the possibility that a block of tumor-only samples might perform well if done relative to the REFSAMPLE and ZEROEXPGENES.

##### To do: 
1. Check if the false negatives failed to be amongst the Wang set.  DONE
2. Check if a solid, pure group performs well with the training REFSAMPLE and ZEROEXPGENES
3. I want to see how the other stage cancers perform.
4. Since I always scale and center across each gene, do I rely on training set for that?, and
might that be better given that I no longer have 50/50 healthy/tumor?
5. It would also be interesting to color the PCA plot by the samples that did not correctly predict.
6. Plot various predictors vs. PCA1 and PCA2.

### False Negatives  
I'm going to get the names of the 10 false negative samples
```{r}
dim(stageHealthyDF)[1]
stage3pred <- testPredictions_toil[c((dim(stageHealthyDF)[1]+1):dim(testPredictions_toil)[1]),]
stage3predFN <- names(stage3pred[stage3pred==0])

# now that I've got the 10 names of the stage 3 false negatives, 
# I'd like to compare that to my large Wang set.

# the full set of Wang sample names can be found at:
# /Users/mjk/Desktop/Tresorit_iOS/projects/RNA-Seq/MachineLearningRNASeq/WangFullTCGAHealthySmpNames.csv	
# /Users/mjk/Desktop/Tresorit_iOS/projects/RNA-Seq/MachineLearningRNASeq/WangFullTCGATumorSmpNames.csv
WangTCGAtumorNames_Full <- read.csv("/Users/mjk/Desktop/Tresorit_iOS/projects/RNA-Seq/MachineLearningRNASeq/WangFullTCGATumorSmpNames.csv")
WangTCGAtumorNames_Full <- gsub("(^TCGA\\.[^\\.]+\\.[^\\.]+\\.[0-9]+).*", "\\1", names(WangTCGAtumorNames_Full))

setdiff(stage3predFN, WangTCGAtumorNames_Full)
```
Of the 10 stage3 false negatives, 7 were in the Wang set and 3 were not.
```{r}
WangTCGAhealthyNames_Full <- read.csv("/Users/mjk/Desktop/Tresorit_iOS/projects/RNA-Seq/MachineLearningRNASeq/WangFullTCGAHealthySmpNames.csv")
WangTCGAhealthyNames_Full <- gsub("(^TCGA\\.[^\\.]+\\.[^\\.]+\\.[0-9]+).*", "\\1", names(WangTCGAhealthyNames_Full))
stage3predFN

```


### Try 1-by-1 Sample Normalization Relative to Training Set
It appears, but is not certain, that normalization is the major reason the dataframes grouped by *tumor stage* performed so poorly.  So I'm going to use the *training* dataset as a reference for filtering certain genes and then for performing the normalization.  The gene-level scaling should only require a vector of training means and a vector of training standard deviations.  
As this will involve repeating many steps, I'll create a function for it.  
```{r}
# need: REFNAME, REFSAMPLE, REFSAMPLEUNSCALED for sample-to-sample scaling factors
# need: ZEROEXPGENES for filtering out background genes

# need to clean up stageOneDF, etc, because they have lots of Wang train/test samples from above:
### See if Wang was separated out from TCGA-test sets:

wangTCGAtrainTest <- rownames(wangMatrix)[grepl("^TCGA", rownames(wangMatrix))]  # used as train and test above
wangTCGAtrainTest <- gsub("(^TCGA\\.[^\\.]+\\.[^\\.]+\\.[0-9]+).*", "\\1", wangTCGAtrainTest)
stageOneDF <- stageOneDF[!(rownames(stageOneDF) %in% wangTCGAtrainTest),]   #  Good news.
stageTwoDF <- stageTwoDF[!(rownames(stageTwoDF) %in% wangTCGAtrainTest),]
stageThreeDF <- stageThreeDF[!(rownames(stageThreeDF) %in% wangTCGAtrainTest),]
stageFourDF <- stageFourDF[!(rownames(stageFourDF) %in% wangTCGAtrainTest),]
stageHealthyDF <- stageHealthyDF[!(rownames(stageHealthyDF) %in% wangTCGAtrainTest),]

stageOneOutcome <- rep(1, dim(stageOneDF)[1])
stageTwoOutcome <- rep(1, dim(stageTwoDF)[1])
stageThreeOutcome <- rep(1, dim(stageThreeDF)[1])
stageFourOutcome <- rep(1, dim(stageFourDF)[1])
stageHealthyOutcome <- rep(0, dim(stageHealthyDF)[1])

# pre-requisites: create mean and sd vectors for all filtered genes
REF_MEANS <- apply(TOILTRAINFILTER, 2, mean)
REF_SDS <- apply(TOILTRAINFILTER, 2, sd)


filterScaleNormalizePredict <- function(df, ZEROEXPGENES, REFSAMPLE, REFNAME,
                                        REFSAMPLEUNSCALED, REF_MEANS, REF_SDS,
                                        coefsFullNames, coefsToilNonZero){
   # 1b. convert to natural scale:
   dfNat <- (2^df)-1
   
   # 2. subtract out ZEROEXPGENES, as defined in training set
   dfNatFilt <- dfNat[,-ZEROEXPGENES]
   
   # 2b. represent intensities as fraction of all signals in each sample
   N <- apply(dfNatFilt, 1, sum)
   dfFiltFrac <- apply(dfNatFilt, 2, function(x) x / N)
   
   # 3. Calculate scaling factor, relative to REFSAMPLE, for each sample in healthy3...
   dfSFs <- calcScalingFactors(dfNatFilt, dfFiltFrac, REFSAMPLE,
                                  REFNAME, REFSAMPLEUNSCALED)
   
   # 3b. Apply scaling factors
   dfFiltScaled <- apply(dfNatFilt, 2, function(x) x/dfSFs)
   
   # 4. Remove Non-Predictor Genes from Filtered Test Data, REF_MEANS, REF_SDS
   dfFiltScal42 <- dfFiltScaled[,coefsFullNames[2:length(coefsFullNames)]]
   REF_MEANS_Predictors <- REF_MEANS[coefsFullNames[2:length(coefsFullNames)]]
   REF_SDS_Predictors <- REF_SDS[coefsFullNames[2:length(coefsFullNames)]]
   
   # 5. scale each gene by its stdev and offset by its mean.  Add intercept
   dfFiltScaledSD <- t(apply(dfFiltScal42, 1, function(x){(x - REF_MEANS_Predictors)/REF_SDS_Predictors}))
   dfFiltScaledSD <- cbind(rep(1,dim(dfFiltScaledSD)[1]), dfFiltScaledSD)
   
   # 6. perform predictions
   testPredictions <- ifelse(dfFiltScaledSD %*% coefsToilNonZero > 0, 1, 0)
   return(testPredictions)
}

# healthy sample only:
healthyPreds <- filterScaleNormalizePredict(stageHealthyDF, ZEROEXPGENES, REFSAMPLE, REFNAME,
                            REFSAMPLEUNSCALED, REF_MEANS, REF_SDS, coefsFullNames,
                            coefsToilNonZero)
table(stageHealthyOutcome, healthyPreds)
```
```{r}
# stage 4 only
stage4Preds <- filterScaleNormalizePredict(stageFourDF, ZEROEXPGENES, REFSAMPLE, REFNAME,
                            REFSAMPLEUNSCALED, REF_MEANS, REF_SDS, coefsFullNames,
                            coefsToilNonZero)
table(stageFourOutcome, stage4Preds)
```
100% sensitivity for stage 4 tumors!
```{r}
# stage 3 only
stage3Preds <- filterScaleNormalizePredict(stageThreeDF, ZEROEXPGENES, REFSAMPLE, REFNAME,
                            REFSAMPLEUNSCALED, REF_MEANS, REF_SDS, coefsFullNames,
                            coefsToilNonZero)
table(stageThreeOutcome, stage3Preds)
```
98.0% sensitivity for stage 3 tumors!

```{r}
# stage 2 only
stage2Preds <- filterScaleNormalizePredict(stageTwoDF, ZEROEXPGENES, REFSAMPLE, REFNAME,
                            REFSAMPLEUNSCALED, REF_MEANS, REF_SDS, coefsFullNames,
                            coefsToilNonZero)
table(stageTwoOutcome, stage2Preds)
```
98.4% sensitivity for stage 2 tumors!
```{r}
# stage 1 only
stage1Preds <- filterScaleNormalizePredict(stageOneDF, ZEROEXPGENES, REFSAMPLE, REFNAME,
                            REFSAMPLEUNSCALED, REF_MEANS, REF_SDS, coefsFullNames,
                            coefsToilNonZero)
table(stageOneOutcome, stage1Preds)
```
100% sensitivity for stage 1 tumors!

Overall, I have 98.6% sensitivity.



##### Now that I'm normalizing straight from the training references, specificity rose to 98.4%, while retaining 100% sensitivity.
















