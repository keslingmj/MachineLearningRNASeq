---
title: "Toil_Selection"
author: "Michael Kesling"
date: "9/27/2019"
output: rmarkdown::github_document 
---
This particular document takes the Toil-normalized TCGA and GTEx breast cancer samples and runs machine learning algorithms on them.  Importantly, the only sample-to-sample normalization performed in quantile-quantile normalization relative to a single reference sample.  No batch normalization is performed at this point,  as it's the simplest scenario for test samples processed in the clinic.

The data were downloaded from the UCSC server at:
https://xenabrowser.net/datapages/?cohort=TCGA%20TARGET%20GTEx&removeHub=https%3A%2F%2Fxena.treehouse.gi.ucsc.edu%3A443
There are 2 relevant *gene expression RNAseq* datasets there.  *RSEM expected_count (n=19,109)* which is used in this document, and *RSEM expected_count (DESeq2 standardized) (n=19,039)* which was used in the *Toil_Norm.Rmd* file.




```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(matrixStats)

######## FUNCTIONS NOT TO BE PRINTED IN MARKDOWN DOC:
scaleData <- function(DM, MEAN=TRUE, ROW=FALSE){
   # this function takes a data matrix, DM, and scales the data by each row's
   # standard deviation (if ROW=TRUE).  If ROW=FALSE, then all scaling will be
   # performed by column.  It may also first subtract off the (row)'s mean if
   # MEAN=TRUE.  For (rows) whose SD=0, they are set aside and added back once
   # the normalization is finished
   # We assume that counts have already been normalized across samples!!
   rowcol <- ifelse(ROW==TRUE, 1, 2)          # normalization by row or column
   rowcolInv <- ifelse(rowcol==1, 2, 1)       # inverse val needed for norm
   SD <- apply(DM, rowcol, sd)                # calc std deviations
   numSDzeros <- sum(SD==0)
   # remove row / col if SD == 0
   if(numSDzeros>0){                          # rm row/col if SD == 0
      zeroSD <- which(SD == 0)                # id examples with zero SD
      DM <- ifelse(rowcol==2, list(DM[, -zeroSD]), list(DM[-zeroSD,]))[[1]]
      SD <- SD[-zeroSD]
   }

   means <- apply(DM, rowcol, mean)
   
   # apply normalization with or without mean subtraction:
   if(MEAN==FALSE){
      DM <- t(apply(DM, rowcolInv, function(x){x / SD}))
   }
   else{
      DM <- t(apply(DM, rowcolInv, function(x){(x - means) / SD}))
   }

   if(rowcol == 1){           # transpose matrix if normalization is across rows
      DM <- t(DM)
   }
   
   # add back all-zero row / column taken out earlier (if done at all)
   if(numSDzeros>0){
      if(rowcol ==1){
         zeros <- matrix(rep(0, length(zeroSD)*dim(DM)[2]), ncol=dim(DM)[2])
         rownames(zeros) <- names(zeroSD)
         DM <- rbind(DM, zeros)
      }
      else{
         zeros <- matrix(rep(0, length(zeroSD)*dim(DM)[1]), nrow=dim(DM)[1])
         colnames(zeros) <- names(zeroSD)
         DM <- cbind(DM, zeros)
      }
   }
   return(DM)
}
```
### Subsetting Toil Data

As I'm only looking at just under 400 Breast Cancer samples that were previously selected, I'll subset the very large Toil RSEM file (19k samples).

The samples I'm interested in are located in a file called wangBreastFPKM398_Attrib.txt, created earlier.  While this file contains FPKM counts, I'm only pulling out the sample names from it.

Additionally, I'm going to convert the Ensemble IDs to the more readable HUGO gene IDs.

I start by grabbing the Wang sample names, the Toil sample names, and finding the overlap between the two.

```{r}
require(dplyr)
require(magrittr)
wangMatrix <- read.table("/Users/mjk/Desktop/Tresorit_iOS/projects/RNA-Seq/data/wangBreastFPKM398_Attrib.txt", header=TRUE) # rownames okay now
wangSelectedSamples <- colnames(wangMatrix)
wangTCGAsamples <- wangSelectedSamples[grep("^TCGA", wangSelectedSamples)] %>%
   {gsub("\\.", "-", .)} %>% 
   {gsub("([TCGA]-[^-]+[-][^-]+[-][^-]+)[-].*", "\\1", .)} %>% 
   {gsub("[AB]$", "", .)}

wangGTEXsamples <- wangSelectedSamples[grep("^GTEX", wangSelectedSamples)] %>%
   {gsub("\\.", "-", .)}

wangSamples <- c(wangGTEXsamples, wangTCGAsamples)


toilSampleNames <- read.table("/Users/mjk/RNA-Seq_2019/TOIL_Data/TcgaTargetGtex_gene_expected_count", sep="\t", nrows = 1, stringsAsFactors = FALSE)
#toilSampleNames <- toilSampleNames[1,2:length(toilSampleNames)]


multiGrep <- function(var1, var2){
   return(grep(var1, var2))
}

wangSampleMapping <- sapply(wangSamples, multiGrep, var2=toilSampleNames)

# missing samples in TOIL set:
missingSamples <- wangSampleMapping[grep("integer", wangSampleMapping)] #15 missing
wangSamplesPresent <- setdiff(wangSamples, names(missingSamples))
```
15 of the Wang samples are missing in the Toil dataset.  I'll therefore be working with 380 samples after the 3 male samples are subtracted out.


Next, I read in the toil dataset (8GB+) and subset it by the Wang sample labels.
```{r}
# code only run the first time:
while(FALSE){
   toilData <- read.table("/Users/mjk/RNA-Seq_2019/TOIL_Data/TcgaTargetGtex_gene_expected_count", header=TRUE, stringsAsFactors = FALSE)

   
   # QA:
   sum(gsub("-", "\\.", toilSampleNames) %in% colnames(toilData)) == length(toilSampleNames)
   
   
   relevantCols <- unique(sort(c(1,unlist(wangSampleMapping[grep("integer", wangSampleMapping, invert=TRUE)], use.names = FALSE)))) #includes capturing gene names
   
   write.table(paste(relevantCols, collapse=","), "wangSamplesRSEM.uniq", sep=",",
               row.names = FALSE, col.names = FALSE)
   
   
   toilSubset <- toilData[, relevantCols]              # subset data
   
   #check that all cols got selected:
   all(gsub("-", ".", wangSamplesPresent) %in% colnames(toilSubset))
   
   write.table(toilSubset, "toilSubsetRSEM382.txt", sep="\t", row.names=FALSE)
   rm(toilData)
}
```

```{r}
# just read already-subsetted dataframe
toilSubset <- read.table("toilSubsetRSEM382.txt", sep="\t", header=TRUE)
rownames(toilSubset) <- toilSubset$sample
```
Next, I add gene names to the dataframe based on the Ensembl ID:
```{r}
require(dplyr)
toilGeneAnnot <- read.table("~/RNA-Seq_2019/TOIL_Data/gencode.v23.annotation.gene.probemap",
                            header=TRUE)
id2gene <- setNames(as.list(as.character(toilGeneAnnot$gene)),
                    toilGeneAnnot$id)
toilSubset <- toilSubset %>% tibble::rownames_to_column()
toilSubset <- toilSubset %>% mutate(gene=id2gene[toilSubset$rowname])
```
Next, I reorder the toilSubset data frame to group "like" samples and make the gene name the row name.
```{r}
colReOrder <- grep("^GTEX", colnames(toilSubset))
colReOrder <- c(colReOrder, grep("11$", colnames(toilSubset)))
colReOrder <- c(colReOrder, grep("01$", colnames(toilSubset)))
tmp <- toilSubset[,colReOrder]
rownames(tmp) <- paste0(toilSubset$gene, "-", toilSubset$rowname)
toilSubset <- tmp
rm(tmp)
```

### Create Test and Training Sets
At this point, all we've done is grabbed the Toil RSEM output data and subsetted
it with the Wang sample lists.  It's still in log2-format.

Next:
1. break into Test and Train  
2. perform edgeR normalization with a reference sample to control for depth-of-sequencing effects.  Use same reference for training and (future) test set  
3.filter out genes (independent if possible)
4. look at overall structure using t-SNE and PCA
5. Perform ML

```{r}
# cleanup toilSubset and transpose it   NOT NEEDED ANYMORE
#rownames(toilSubset) <- toilSubset$genename
#toilSubsetWide <- t(toilSubset[,2:dim(toilSubset)[2]])

toilSubsetWide <- t(toilSubset)

require(caTools)
set.seed(233992812)
outcome <- c(rep(0, 185), rep(1, 197))  # 0 = healthy, 1 = tumor

# bind outcome variable on data frame for even, random partitioning
toilSubsetWide <- data.frame(cbind(toilSubsetWide, outcome))
idxTrain <- sample.split(toilSubsetWide$outcome, SplitRatio = 0.75)
# QA
sum(idxTrain)/length(idxTrain)  # 75% observations in training set OK

# create training and test predictor sets and outcome vectors:
toilTrain <- subset(toilSubsetWide, idxTrain==TRUE)
outcomeTrain <- subset(toilSubsetWide$outcome, idxTrain==TRUE)
toilTest <- subset(toilSubsetWide, idxTrain==FALSE)
outcomeTest <- subset(toilSubsetWide$outcome, idxTrain==FALSE)

# remove outcome variable from predictor matrices:
toilTrain <- toilTrain %>% select(-outcome)
toilTest <- toilTest %>% select(-outcome)
# convert back to matrices:
toilTrain <- as.matrix(toilTrain)
toilTest <- as.matrix(toilTest)
```
### edgeR Sample-to-Sample Normalization
Next, we select a reference sample within the training set and relative to that reference, we perform edgeR sample-to-sample normalization, one sample at a time.  The methodology can be found in Robinson MD and Oshlack A, "A scaling normalization method for differential expression analysis of RNA-seq data", Genome Biology, 11: R26 (2010).
```{r}

### 1. remove genes with near-0 expression
# We know that there are about 9103 genes that are never expressed, but there are
# over 25000 genes whose 75th quantile-level expression is under 2^(0.2) - 1 = 0.14 counts.
# We really don't want to deal with those genes in selecting a reference sample, etc.

# sum(apply(toilTrain, 2, function(x) sum(x==0))==dim(toilTrain)[1])  # there are 9103
# transcripts that are never expressed across the 287 training examples!

hist(apply(toilTrain, 1, function(x) quantile(x)[4]))
```
We are going to filter out genes whose 75th quantile across 287 samples is less than 0.14 counts (log2(counts) < 0.2).
```{r}
zeroExpGenes <- which(apply(toilTrain, 2, function(x) quantile(x)[4]) < 0.2)
toilTrainFilter <- toilTrain[,-zeroExpGenes]  # down to 32k transcripts
```
It should be noted that the range of the 75th quantile *across samples* was 2^7-fold when only the genes that were zero in all samples were filtered.  When we filtered genes whose 75th gene-quantile was less than 0.14 (natural scale), the 75th quantile *across samples* range went down to 2^3-fold.
```{r}
# Let's look at some scaling stats in the natural scale
toilTrainNat <- ((2^toilTrain)-1)    # natural scale
N <- apply(toilTrainNat, 1, sum)
hist(N)
sd(N)/mean(N)                        # CV is 0.33 287 training samples. range=5.7 fold
quart3 <- apply(toilTrainNat, 1, function(x) quantile(x)[4])
sd(quart3)/mean(quart3)              # 0.35 CV of quartiles. range=6.3-fold
# thusfar, all the data are unfiltered

# next, let's filter only all-0 genes
allZeros <- which(apply(toilTrainNat, 2, sum)==0)
ttnNozeros <- toilTrainNat[,-allZeros]
quart3 <- apply(ttnNozeros, 1, function(x) quantile(x)[4])
sd(quart3)/mean(quart3)              # still 0.35

# next, let's filter all 3rd quartile < 0.14 counts--filter criterion in log-scale:
zeroExpGenes <- which(apply(toilTrain, 2, function(x) quantile(x)[4]) < 0.2)    ############## USED LATER
ttnNoNearzeros <- toilTrainNat[,-zeroExpGenes]
quart3 <- apply(ttnNoNearzeros, 1, function(x) quantile(x)[4])
sd(quart3)/mean(quart3)              # CV drops slightly to 0.336
hist(log2(quart3 + 1))
```
Having filtered out ~28k genes whose expression is nil or very, very close to that.  The range stays the same, which is 2.5 on the log scale.  Only subtraction, and not division, is relevant on this scale.  This matrix, called "ttnNoNearzeros" is on the natural scale, has only the 287 training samples, and 32177 genes.  We will stick to these same genes when filtering test data before sample-to-reference normalization.  

### Selecting a Reference Sample for Sample-to-Sample Normalization
```{r}
# first we re-name our filtered matrix:
toilTrainFilter <- ttnNoNearzeros
# we remove matrices and lists we no longer need:
rm(toilGeneAnnot)
rm(toilSampleNames)
rm(zeroExpGenes)
rm(ttnNozeros)
rm(allZeros)
rm(quart3)
rm(ttnNoNearzeros)

### Define Functions
pickRefSample <- function(X, logged=FALSE){  # X is matrix with samples as rows
                   # representative reference sample selected via edgeR specs
                   # this script assumes data are on natural scale.
   Xnat <- if(logged==TRUE) ((2^X)-1) else X  # put in natural scale
   N <- apply(Xnat, 1, sum)
   scaledX <- apply(Xnat, 2, function(x) x / N)
   thirdQuartiles <- apply(scaledX, 1, function(x) quantile(x)[4])
   med <- median(thirdQuartiles)
   refSampleName <- names(sort(abs(thirdQuartiles - med))[1])
   return(list(refSampleName, scaledX))
}
### 2. select a reference sample against which other samples will be scaled
lst <- pickRefSample(toilTrainFilter, logged=FALSE) 
refName <- lst[[1]]                                                         #### USED LATER
toilTrainScaled <- lst[[2]]
refSample <- toilTrainScaled[which(rownames(toilTrainScaled) == refName),]  #### USED LATER
refSampleUnscaled <- toilTrainFilter[refName,]                              #### USED LATER
print(paste0("The sample chosen to the the Reference Sample for the purposes of Sample-to-Sample Normalization is ",
        refName, "."))
```
### Scaling Training Samples Relative to the Chosen Reference Sample (Sample-to-Sample Normalization)
```{r}
weightedTrimmedMean <- function(refSample, testSample, refName, testName, testSmpUnscaled, refSmpUnscaled){
   # refSample and testSample are both numeric vectors, and we assume data are on natural
   # scale.  The values are represented as fraction of total counts.  So
   # df should be 'toilTrainFilter' which are not as fracction of total counts, as
   # this is needed in computing the weights and TMM in the final step.
   # BTW, "testSample" does not infer that the sample is from the test set, but only
   # that it's a sample being scaled relative to the refSample.
   # refSmpUnscaled could be derived from df, but only with training sets and not 
   # with test sets.  So it is supplied separately.
   
   
   # first filter off any genes that are zero in refSample or testSample
   # # but for Yg• ≠ 0.

   refZeros <- which(refSample==0)
   smpZeros <- which(testSample==0)
   unionZeros <- sort(unique(append(refZeros, smpZeros)))
   refSampleFilt <- refSample[-unionZeros]
   testSampleFilt <- testSample[-unionZeros]
   
   # calculate M and A only for filtered genes   
   refLog <- log2(refSampleFilt)
   smpLog <- log2(testSampleFilt)
   M <- refLog - smpLog           # ref sample in numerator
   A <- 0.5 * (refLog + smpLog)   
   
   # grab middle 40% of M and middle 90% of A
   M_limits <- quantile(M, probs = seq(0,1,0.05))[c(7,15)]  # diagnostic
   A_limits <- quantile(A, probs = seq(0,1,0.05))[c(2,20)]  # diagnostic
   
   A_middle90 <- names(A[(A >= A_limits[1] & A <= A_limits[2]) == TRUE])
   M_middle40 <- names(M[(M >= M_limits[1] & M <= M_limits[2]) == TRUE])
   
   
   # grab genes names in intersection of A_middle90 and M_middle40
   genes4norm <- dplyr::intersect(A_middle90, M_middle40)

   #########
   # Nk and Nr must be relative to the genes that remain.
   # further, Ygk and Ygr need to be recalculated relative to that value
   #########
   # grab 2 samples on Norm Genes on Natural Scale that aren't a fraction of
   # the total sample counts.  refSmpUnscaled is separately supplied so that
   # this function will work with scaling test sets.
   refSelectNat <- refSmpUnscaled[genes4norm]
   testSelectNat <- testSmpUnscaled[genes4norm]
   
   # subset M for normalization genes
   M_norm <- M[genes4norm]
   
   # calculate Nk and Nr
   Nr <- sum(refSelectNat)
   Nk <- sum(testSelectNat)
   
   # calculate weights
   RefDiff <- Nr - refSelectNat
   TestDiff <- Nk - testSelectNat
   RefProd <- Nr * refSelectNat
   TestProd <- Nk * testSelectNat
   weights <- (RefDiff/RefProd) + (TestDiff/TestProd)
   
   # calculate Trimmed Mean scaling factor
   TMM_log2 <- sum(M_norm * weights)/sum(weights)   # some NaN here
   TMM <- 2^TMM_log2
   return(TMM)
}


### 3. go through each sample in training set and get scaling factor
ScalFact <- list()
samples <- rownames(toilTrainFilter)
i <- 1
for(trainSampleName in samples){
   trainSample <- toilTrainScaled[i,]
   trainUnscaled <- toilTrainFilter[i,]
   scalingFactor <- weightedTrimmedMean(refSample, trainSample, refName, trainSampleName, trainUnscaled,
                                        refSampleUnscaled)
   ScalFact <- c(ScalFact, scalingFactor)
   i = i+1
}
ScalFact <- unlist(ScalFact)

### 4. Scale toilTrainFilter matrix using scaling factors
dim(toilTrainFilter)
toilTrainFiltScaled <- apply(toilTrainFilter, 2, function(x) x/ScalFact)
### we now have a scaled training matrix
```
### Distribution of 75th Quantiles of Scaled Training Samples
```{r}
require(ggplot2)
# Let's start with distribution of median counts for each gene.
quant75LevelsGenes <- apply(log2(toilTrainFiltScaled + 1), 1, quantile)[4,]
hist(quant75LevelsGenes, breaks=100, main="75th quantile log2(normalized counts)")
```
Remember that these values are on the log2 scale!  Therefore, genes under log2(exp) = 5 are likely very noisy.  For now, I'm only going to filter out the lowest genes:


### t-SNE to view Cancer/Healthy Diagnosis Partitioning among training samples
```{r}
require(Rtsne);
require(ggplot2);
set.seed(31234)
tSNEout_toilSN <- Rtsne(toilTrainFiltScaled, dims=2)
prognosis <- c(rep(1, 59), rep(2,80), rep(3, 148))       # 1/2 = healthy, 3 = cancer
tsne_plot_toil <- data.frame(x=tSNEout_toilSN$Y[,1], y = tSNEout_toilSN$Y[,2], col=prognosis)
colors3pal <- c("#FDAE6B", "#E6550D",  "#56B4E9")
#tsne_plot_3class <- data.frame(x=tSNEout_full$Y[,1], y = tSNEout_full$Y[,2], col=prognosis)
ggplot(tsne_plot_toil) + 
   geom_point(aes(x=x, y=y, color=as.factor(col))) + 
   ggtitle("t-SNE Plot of Training Data Using All Filtered Predictors of Toil Training Data") +
   scale_color_manual(name="Category",
                      breaks = c("1", "2", "3"),
                      values = c(colors3pal[1], colors3pal[2], colors3pal[3]),
                      labels = c("Healthy-GTEX", "Healthy-TCGA", "Cancer-TCGA"))
```
We can see that although these samples were not subject to batch normalization (such as ComBat, SVA), there is good segregation of healthy samples and tumors even though the healthy samples come from 2 different projects: TCGA and GTEx.  On the other hand, we see that there is segretation between those groups, but it still allows a separation of healthy / tumor.


### PCA Analysis

The t-SNE plot shows significant batch effects between healthy TCGA samples and healthy GTEX samples.  The Healthy-TCGA don't cluster as well as they did with DESeq2-normalized samples in another document.



### Logistic Regression with Lasso Regularizer on Toil Data
I'd like to compare the performance on this breast cancer dataset in the absence of batch normalization (ComBat).
```{r, fig.height=8, fig.width=8}
###############
### Fitting Logistic Regression with Lasso Regularizer on toilSubNatural matrix
require(glmnet);
require(ggplot2);
# install_github("ririzarr/rafalib")
require(rafalib);

# scale each gene by its standard deviation and center it by its mean so that all coefficients
# are on equal footing
toilTrainFiltScaledSD <- scaleData(toilTrainFiltScaled, TRUE, FALSE)

set.seed(1011)
fitToil.lasso <- glmnet(toilTrainFiltScaledSD, outcomeTrain, family="binomial",
                           alpha = 1)
plot(fitToil.lasso, xvar="lambda", label=TRUE)

```
It's clear that scaling the predictors before Lasso enables many more to be used.  It would be interesting to see how many of these genes have a low level of expression (and therefore might be noisy data).

### Cross-Validating the Model to Pick the Smallest, Well-Performing Model
I'm going to look at cross-validating the model in order to pick the simplest one that performs well.
```{r}
set.seed(1011)
cv.Toil.lasso <- cv.glmnet(toilTrainFiltScaledSD, outcomeTrain, family="binomial", alpha=1) 
                      #type.measure = "deviance")
plot(cv.Toil.lasso)
```
We can see that 42 predictors gives us a model whose deviance is within 1-standard deviation from the minimum.  

### Select the Model by Capturing the Coefficients
```{r}
coefsToil <- coef(fitToil.lasso, s=cv.Toil.lasso$lambda.1se)
allCoefsNames <- rownames(coefsToil)
idx <- which(coefsToil!= 0)
coefsFullNames <- allCoefsNames[idx]

coefsToilNonZero <- coefsToil[which(coefsToil!= 0)]
coefsShortNames <- gsub("\\..*$", "", coefsFullNames)
coefsDF <- cbind(coefsShortNames, coefsToilNonZero)
#print(c("The (cleaned-up) names of the predictors are "))
print(coefsDF)
```
when performing predictions, we'll need *coefsFullNames* and *coefsToilNonZero*

### Filter and Scale Test Data.  (A) Relying on Training Data for Zero-Filtering and Scaling of Test Data
```{r}
### 1. Filter out near-zero genes as defined with training data:
###  WE ARE USING DATA FROM THE TRAINING SET #################
#    THIS IS NEEDED IF 
toilTestFilter <- toilTest[,-zeroExpGenes]   # using Same Gene List Filter (near-zero) established in Training Set
# now 95 x 32177 on log2(x+1) scale


### 2. Scale test data as fraction of all sample counts
## define scaling function (same logic as with training data)
toilTestFiltNat <- 2^(toilTestFilter) - 1

scaleTestSamples <- function(X, logged=FALSE){  # X is matrix with samples as rows
                   # representative reference sample selected via edgeR specs
                   # this script assumes data are on natural scale.
   Xnat <- if(logged==TRUE) ((2^X)-1) else X  # put in natural scale
   N <- apply(Xnat, 1, sum)
   scaledX <- apply(Xnat, 2, function(x) x / N)
   return(scaledX)
}
toilTestScaled <- scaleTestSamples(toilTestFiltNat, logged=FALSE)


### 3. Individually scale test samples relative to training reference sample.  Each scaling is
#      independent of other scalings.
ScalFact <- list()
samples <- rownames(toilTestFilter)

i <- 1
for(testSampleName in samples){         # some of the passed variables were created in training set
   testSample <- toilTestScaled[i,]
   testUnscaled <- toilTestFiltNat[i,]
   #print(c("lengths", length(testSample), length(testUnscaled), length(refSample), length(refSampleUnscaled)))
   #print(c("NAsbeforefunction", any(is.na(testSample)), any(is.na(testUnscaled))))
   
   scalingFactor <- weightedTrimmedMean(refSample, testSample, refName, testSampleName, testUnscaled, refSampleUnscaled)
   ScalFact <- c(ScalFact, scalingFactor)
   i = i+1
}
ScalFact <- unlist(ScalFact)

### 4. Scale toilTrainFilter matrix using scaling factors
dim(toilTestFiltNat)
toilTestFiltScaled <- apply(toilTestFiltNat, 2, function(x) x/ScalFact)

### 5. scale each gene by its standard deviation and center it by its mean so that all coefficients
#      are on equal footing
toilTestFiltScaledSD <- scaleData(toilTestFiltScaled, TRUE, FALSE)       # this would not be possible for individual samples!!!!!!
toilTestFiltScaledSD <- cbind(rep(1,dim(toilTestFiltScaledSD)[1]), toilTestFiltScaledSD) #add intercept column
```
### Create Confusion Matrix for Test Data

```{r}
testPredictions_toil <- ifelse(toilTestFiltScaledSD %*% coefsToil > 0, 1, 0)
table(outcomeTest, testPredictions_toil)
```
I am seeing 100% specificity and 100% selectivity!

### Filter and Scale Test Data.  (B) Not Relying on Training Data for Zero-Filtering and Scaling of Test Data

```{r}
toilTest <- cbind(1, toilTestScaled)
colnames(toilTest)[1] <- "(Intercept)"
toilTest <- as.matrix(toilTest)

coefsToil <- coef(fitToil.lasso, s=cv.Toil.lasso$lambda.1se)
testPredictions_Toil <- ifelse(toilTest %*% coefsToil > 0, 1, 0)
table(outcomeTest, testPredictions_Toil)
```
### Look at Function of Predictors






